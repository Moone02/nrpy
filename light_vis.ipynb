{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c894937",
   "metadata": {},
   "source": [
    "<a id='plotting'></a>\n",
    "# Step 1: Visualization and Analysis\n",
    "\n",
    "This notebook is dedicated to processing and visualizing the output of the C-language geodesic integrator. The cells here are for analysis and are not part of the C code generation process. They are designed to be run *after* the C code has been compiled and executed, and has produced a `light_blueprint.bin` file.\n",
    "\n",
    "The Python code below uses standard libraries like `numpy`, `matplotlib`, and `Pillow` to:\n",
    "1.  Define a `numpy` data type that exactly matches the binary format of the `blueprint_data_t` C struct.\n",
    "2.  Load the binary `light_blueprint.bin` file into a structured `numpy` array.\n",
    "3.  Perform statistical analysis on the ray-tracing results.\n",
    "4.  Generate a variety of plots, including false-color images of the lensed accretion disk and histograms of the data.\n",
    "\n",
    "**Notebook Status:** <font color='green'><b>Validated</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f6749",
   "metadata": {},
   "source": [
    "<a id='blueprint_dtype'></a>\n",
    "## 1.a: Defining the Blueprint Data Structure\n",
    "\n",
    "Before we can read the binary output file from our C code, we must tell Python exactly what the structure of the data is. The `light_blueprint.bin` file is not a standard image file; it is a raw binary dump of the `blueprint_data_t` C structs, one after another.\n",
    "\n",
    "This cell defines a `numpy` structured data type (`dtype`) that precisely mirrors the C struct. Each field is given a name (e.g., `'termination_type'`), a data type (e.g., `np.int32` for a 32-bit integer), and a size. This `BLUEPRINT_DTYPE` acts as a template, allowing `numpy` to correctly parse the binary file into a structured array, making the data easily accessible in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92faa911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Union, Optional, List, Tuple\n",
    "import os\n",
    "\n",
    "# Define the exact structure of a record in the new light_blueprint.bin file.\n",
    "# This must match the final C struct 'blueprint_data_t'.\n",
    "BLUEPRINT_DTYPE = np.dtype([\n",
    "    ('termination_type', np.int32),\n",
    "    ('y_w', 'f8'), \n",
    "    ('z_w', 'f8'),\n",
    "    # Fields for DISK hits\n",
    "    ('stokes_I', 'f8'),\n",
    "    ('lambda_observed', 'f8'),\n",
    "    # Fields for SOURCE PLANE hits\n",
    "    ('y_s', 'f8'),\n",
    "    ('z_s', 'f8'),\n",
    "    # Fields for CELESTIAL SPHERE hits\n",
    "    ('final_theta', 'f8'),\n",
    "    ('final_phi', 'f8'),\n",
    "    # Diagnostic fields\n",
    "    ('L_w', 'f8'),\n",
    "    ('t_w', 'f8'),\n",
    "    ('L_s', 'f8'),\n",
    "    ('t_s', 'f8'),\n",
    "], align=False)\n",
    "\n",
    "print(\"Libraries and new blueprint data type (BLUEPRINT_DTYPE) defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8974d8aa",
   "metadata": {},
   "source": [
    "<a id='debug_plot'></a>\n",
    "## 1.b: Debug Trajectory Visualizer\n",
    "\n",
    "When debugging the integrator, it is often useful to trace the path of a single photon. When the C code is run in `debug_mode`, it outputs a text file (`photon_path.txt`) containing the full trajectory (position and momentum) of a single ray at each step of the GSL integrator.\n",
    "\n",
    "The function `plot_photon_trajectory_from_debug` reads this text file and generates a 3D plot of the photon's path through spacetime. It also plots a sphere at the origin representing the black hole's event horizon to provide a visual reference. This is an invaluable tool for diagnosing issues with the integrator or for gaining intuition about how geodesics behave in curved spacetime.\n",
    "\n",
    "### Function: `plot_photon_trajectory_from_debug()`\n",
    "*   **Inputs:**\n",
    "    *   `project_dir`: The path to the C project directory.\n",
    "    *   `input_filename`: The name of the debug trajectory file to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f0b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_photon_trajectory_from_debug(\n",
    "    project_dir: str = \"project/photon_geodesic_integrator\",\n",
    "    input_filename: str = \"photon_path_numerical.txt\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads trajectory data from the C code's debug output and generates a\n",
    "    simple 3D plot of the photon's path with a sphere at the origin.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Photon Trajectory Plot from Debug File ---\")\n",
    "    \n",
    "    # --- 1. Construct the full path and load the data ---\n",
    "    full_path = os.path.join(project_dir, input_filename)\n",
    "    \n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"ERROR: Trajectory file not found at '{full_path}'\")\n",
    "        print(\"Please ensure you have compiled and run the C code in debug mode successfully.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Load the data, skipping the header row.\n",
    "        # Set invalid_raise=False to handle potential trailing empty lines.\n",
    "        data = np.loadtxt(full_path, skiprows=1, ndmin=2)\n",
    "        if data.shape[0] == 0:\n",
    "            print(\"ERROR: Trajectory file is empty.\")\n",
    "            return\n",
    "            \n",
    "        # Columns: 0:lambda, 1:t, 2:x, 3:y, 4:z, ...\n",
    "        x_coords = data[:, 2]\n",
    "        y_coords = data[:, 3]\n",
    "        z_coords = data[:, 4]\n",
    "        print(f\"Successfully loaded {len(x_coords)} data points from trajectory file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load or parse the data file '{full_path}'.\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Set up the 3D plot ---\n",
    "    plt.style.use('dark_background')\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # --- 3. Plot the photon's trajectory ---\n",
    "    ax.plot(x_coords, y_coords, z_coords, label='Photon Path', color='cyan', lw=2)\n",
    "    \n",
    "    # Mark the start (camera) and end points\n",
    "    ax.scatter(x_coords[0], y_coords[0], z_coords[0], color='lime', s=100, label='Start (Camera)', marker='o', depthshade=False)\n",
    "    ax.scatter(x_coords[-1], y_coords[-1], z_coords[-1], color='red', s=100, label='End Point', marker='X', depthshade=False)\n",
    "\n",
    "    # --- 4. Plot a simple sphere at the origin ---\n",
    "    radius = 2.0 # Represents r=2M, the Schwarzschild event horizon\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "    x_bh = radius * np.outer(np.cos(u), np.sin(v))\n",
    "    y_bh = radius * np.outer(np.sin(u), np.sin(v))\n",
    "    z_bh = radius * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "    ax.plot_surface(x_bh, y_bh, z_bh, color='grey', alpha=0.5, rstride=5, cstride=5)\n",
    "    \n",
    "    # --- 5. Customize the plot ---\n",
    "    ax.set_xlabel('X (M)', fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel('Y (M)', fontsize=12, labelpad=10)\n",
    "    ax.set_zlabel('Z (M)', fontsize=12, labelpad=10)\n",
    "    \n",
    "    # Set aspect ratio to be equal to avoid distortion\n",
    "    max_range = np.array([x_coords.max()-x_coords.min(), y_coords.max()-y_coords.min(), z_coords.max()-z_coords.min()]).max() / 2.0\n",
    "    if max_range == 0: max_range = np.max(np.abs(data[:, 2:5]))\n",
    "    mid_x = (x_coords.max()+x_coords.min()) * 0.5\n",
    "    mid_y = (y_coords.max()+y_coords.min()) * 0.5\n",
    "    mid_z = (z_coords.max()+z_coords.min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "    ax.set_title(\"Photon Trajectory (Debug Run)\", fontsize=16)\n",
    "    ax.legend()\n",
    "    ax.view_init(elev=15, azim=60)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1200f1f",
   "metadata": {},
   "source": [
    "<a id='blueprint_inspector'></a>\n",
    "## 1.c: Blueprint Data Inspector\n",
    "\n",
    "The `light_blueprint.bin` file contains a wealth of information. This cell defines the `view_binary_blueprint` function, a utility for quickly inspecting the raw contents of the blueprint file.\n",
    "\n",
    "It reads the binary file using the `BLUEPRINT_DTYPE` template and prints a formatted table showing a sample of the records. For each ray, it displays its termination type and the key physical results associated with that termination (e.g., the observed intensity for a disk hit, or the final angles for a celestial sphere hit). This is a useful first step for verifying that the C code is producing sensible output.\n",
    "\n",
    "### Function: `view_binary_blueprint()`\n",
    "*   **Inputs:**\n",
    "    *   `blueprint_filename`: The path to the `light_blueprint.bin` file.\n",
    "    *   `max_rays_to_print`: The number of sample records to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965217d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def view_binary_blueprint(\n",
    "    blueprint_filename=\"project/photon_geodesic_integrator/light_blueprint.bin\",\n",
    "    max_rays_to_print=20\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads the new binary blueprint file and prints its raw contents in a\n",
    "    human-readable, context-aware format.\n",
    "    \n",
    "    UPDATED to understand the new, detailed termination_type_t enum.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(blueprint_filename):\n",
    "        print(f\"Error: Blueprint file not found at '{blueprint_filename}'\")\n",
    "        return\n",
    "\n",
    "    # This function now uses the global BLUEPRINT_DTYPE defined in the previous cell.\n",
    "    data = np.fromfile(blueprint_filename, dtype=BLUEPRINT_DTYPE)\n",
    "    \n",
    "    print(f\"--- Raw Blueprint Data Inspector (Debug-Enabled Version) ---\")\n",
    "    print(f\"Total records read from file: {len(data)}\\n\")\n",
    "    print(\"Printing a sample of records...\")\n",
    "    \n",
    "    # --- UPDATED ENUM MAPPING ---\n",
    "    # This map now reflects the exact integer values from your requested C enum.\n",
    "    term_str_map = {\n",
    "        0: \"FAIL_PT_BIG\", 1: \"DISK\", 2: \"SOURCE_PLANE\", 3: \"SPHERE\",\n",
    "        4: \"ACTIVE\", 5: \"FAIL_GSL\", 6: \"FAIL_GENERIC\",\n",
    "        7: \"FAIL_T_MAX\", 8: \"FAIL_SLOT\"\n",
    "    }\n",
    "    print(\"Enum Mapping:\", \", \".join([f\"{k}={v}\" for k, v in term_str_map.items()]))\n",
    "    \n",
    "    # Updated header for new data fields\n",
    "    header = f\"{'Ray#':<8} | {'TermType':<12} | {'y_w':>8} | {'z_w':>8} | {'Result 1':>12} | {'Result 2':>12}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    if len(data) > max_rays_to_print:\n",
    "        indices_to_print = np.linspace(0, len(data) - 1, max_rays_to_print, dtype=int)\n",
    "    else:\n",
    "        indices_to_print = np.arange(len(data))\n",
    "\n",
    "    for i in indices_to_print:\n",
    "        rec = data[i]\n",
    "        term_type = int(rec['termination_type'])\n",
    "        term_str = term_str_map.get(term_type, \"UNKNOWN\")\n",
    "\n",
    "        res1_str, res2_str = \"N/A\", \"N/A\"\n",
    "        if term_type == 1: # DISK\n",
    "            res1_str = f\"I={rec['stokes_I']:.3e}\"\n",
    "            res2_str = f\"λ={rec['lambda_observed']:.2f}\"\n",
    "        elif term_type == 2: # SOURCE_PLANE\n",
    "            res1_str = f\"y_s={rec['y_s']:.3f}\"\n",
    "            res2_str = f\"z_s={rec['z_s']:.3f}\"\n",
    "        elif term_type == 3: # CELESTIAL_SPHERE\n",
    "            res1_str = f\"θ={rec['final_theta']:.3f}\"\n",
    "            res2_str = f\"φ={rec['final_phi']:.3f}\"\n",
    "        \n",
    "        print(f\"{i:<8} | {term_str:<12} | {rec['y_w']:>8.2f} | {rec['z_w']:>8.2f} | {res1_str:>12} | {res2_str:>12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64e0f07",
   "metadata": {},
   "source": [
    "<a id='blueprint_analyzer'></a>\n",
    "## 1.d: Comprehensive Blueprint Analysis and Visualization\n",
    "\n",
    "This cell defines the `analyze_blueprint` function, which performs a comprehensive statistical analysis of the entire ray-tracing run and generates a suite of plots to visualize the results.\n",
    "\n",
    "The function first loads the entire `light_blueprint.bin` file and segregates the data based on how each ray terminated. It then calculates and prints summary statistics for each outcome, such as the apparent size of the black hole shadow and the range of observed intensities and wavelengths for disk hits.\n",
    "\n",
    "Finally, it generates a multi-panel figure that provides a deep dive into the simulation results:\n",
    "*   **Observed Intensity Map**: A 2D histogram showing the brightness of the accretion disk as seen on the camera's window plane.\n",
    "*   **Observed Wavelength Map**: A scatter plot showing the color (Doppler and gravitational redshift/blueshift) of the disk.\n",
    "*   **Wavelength vs. Radius**: A plot showing the relationship between the observed wavelength and the apparent radius on the camera's window, often revealing the characteristic signature of a rotating disk.\n",
    "*   **Intensity Distribution**: A histogram of the observed intensities.\n",
    "*   **Termination Pie Chart**: A chart showing the percentage of rays that hit the disk, the shadow, the source plane, etc.\n",
    "*   **Outcome by Radius**: A stacked histogram showing what happened to photons as a function of their starting radial position on the camera's window.\n",
    "\n",
    "### Function: `analyze_blueprint()`\n",
    "*   **Inputs:**\n",
    "    *   `blueprint_filename`: The path to the `light_blueprint.bin` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be508e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import os\n",
    "\n",
    "def analyze_blueprint(blueprint_filename=\"project/photon_geodesic_integrator/light_blueprint.bin\"):\n",
    "    \"\"\"\n",
    "    Reads the blueprint file and generates a comprehensive statistical analysis\n",
    "    and a full suite of plots.\n",
    "    \n",
    "    UPDATED Plot 5 to show a breakdown of failure types in the stacked histogram.\n",
    "    \"\"\"\n",
    "    # --- 1. Load Data ---\n",
    "    if not os.path.exists(blueprint_filename):\n",
    "        print(f\"Error: Blueprint file not found at '{blueprint_filename}'\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        data = np.fromfile(blueprint_filename, dtype=BLUEPRINT_DTYPE)\n",
    "    except NameError:\n",
    "        print(\"ERROR: BLUEPRINT_DTYPE is not defined. Please run the cell that defines it first.\")\n",
    "        return\n",
    "        \n",
    "    if len(data) == 0:\n",
    "        print(\"Blueprint file is empty. No analysis to perform.\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Segregate Data by Termination Type (UPDATED for new enum) ---\n",
    "    disk_hits = data[data['termination_type'] == 1]\n",
    "    source_plane_hits = data[data['termination_type'] == 2]\n",
    "    sphere_hits = data[data['termination_type'] == 3]\n",
    "    fail_pt_big_hits = data[data['termination_type'] == 0]\n",
    "    fail_gsl_hits = data[data['termination_type'] == 5]\n",
    "    fail_generic_hits = data[data['termination_type'] == 6]\n",
    "    fail_t_max_hits = data[data['termination_type'] == 7]\n",
    "    fail_slot_hits = data[data['termination_type'] == 8]\n",
    "    all_failure_hits = np.concatenate([\n",
    "        fail_pt_big_hits, fail_gsl_hits, fail_generic_hits,\n",
    "        fail_t_max_hits, fail_slot_hits\n",
    "    ])\n",
    "    num_total_rays = len(data)\n",
    "    num_disk = len(disk_hits)\n",
    "    num_source_plane = len(source_plane_hits)\n",
    "    num_sphere = len(sphere_hits)\n",
    "    num_total_failure = len(all_failure_hits)\n",
    "\n",
    "    print(\"--- Blueprint File Analysis (Debug-Enabled Version) ---\")\n",
    "    print(f\"Total rays in scan: {num_total_rays}\")\n",
    "    print(f\"  Rays that hit the DISK:              {num_disk} ({100.0 * num_disk / num_total_rays:.2f}%)\")\n",
    "    print(f\"  Rays that hit the SOURCE_PLANE:      {num_source_plane} ({100.0 * num_source_plane / num_total_rays:.2f}%)\")\n",
    "    print(f\"  Rays that hit the CELESTIAL_SPHERE:  {num_sphere} ({100.0 * num_sphere / num_total_rays:.2f}%)\")\n",
    "    print(f\"  TOTAL FAILED RAYS (shadow):          {num_total_failure} ({100.0 * num_total_failure / num_total_rays:.2f}%)\")\n",
    "\n",
    "    if num_total_failure > 0:\n",
    "        print(\"    --- Failure Breakdown ---\")\n",
    "        print(f\"    -> GSL Integrator Error:      {len(fail_gsl_hits)} ({100.0 * len(fail_gsl_hits) / num_total_failure:.2f}%)\")\n",
    "        print(f\"    -> |p^t| Exceeded Max:        {len(fail_pt_big_hits)} ({100.0 * len(fail_pt_big_hits) / num_total_failure:.2f}%)\")\n",
    "        print(f\"    -> Integration Time Exceeded: {len(fail_t_max_hits)} ({100.0 * len(fail_t_max_hits) / num_total_failure:.2f}%)\")\n",
    "        print(f\"    -> Slot Manager Error:        {len(fail_slot_hits)} ({100.0 * len(fail_slot_hits) / num_total_failure:.2f}%)\")\n",
    "        print(f\"    -> Generic Failure:           {len(fail_generic_hits)} ({100.0 * len(fail_generic_hits) / num_total_failure:.2f}%)\")\n",
    "        \n",
    "        r_w_failure = np.sqrt(all_failure_hits['y_w']**2 + all_failure_hits['z_w']**2)\n",
    "        if len(r_w_failure) > 0 and np.any(np.isfinite(r_w_failure)):\n",
    "            print(f\"    -> Apparent radius of black hole shadow on window: {np.nanmax(r_w_failure):.4f} M\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # --- 3. Detailed Statistical Analysis ---\n",
    "    if num_disk > 0:\n",
    "        valid_disk_hits = disk_hits[np.isfinite(disk_hits['stokes_I']) & np.isfinite(disk_hits['lambda_observed'])]\n",
    "        if len(valid_disk_hits) > 0:\n",
    "            intensities = valid_disk_hits['stokes_I']\n",
    "            wavelengths = valid_disk_hits['lambda_observed']\n",
    "            print(\"\\n--- Detailed Disk Hit Statistics ---\")\n",
    "            print(\"\\n  Observed Intensity (Stokes I):\")\n",
    "            print(f\"    Min / Max:    {np.min(intensities):.3e} / {np.max(intensities):.3e}\")\n",
    "            print(f\"    Mean / Median:  {np.mean(intensities):.3e} / {np.median(intensities):.3e}\")\n",
    "            percentiles_I = np.percentile(intensities, [10, 25, 75, 90])\n",
    "            print(f\"    Percentiles:  10th={percentiles_I[0]:.3e}, 25th={percentiles_I[1]:.3e}, 75th={percentiles_I[2]:.3e}, 90th={percentiles_I[3]:.3e}\")\n",
    "\n",
    "            print(\"\\n  Observed Wavelength (lambda_obs) in nm:\")\n",
    "            print(f\"    Min / Max:    {np.min(wavelengths):.2f} / {np.max(wavelengths):.2f}\")\n",
    "            print(f\"    Mean / Median:  {np.mean(wavelengths):.2f} / {np.median(wavelengths):.2f}\")\n",
    "            percentiles_L = np.percentile(wavelengths, [10, 25, 75, 90])\n",
    "            print(f\"    Percentiles:  10th={percentiles_L[0]:.2f}, 25th={percentiles_L[1]:.2f}, 75th={percentiles_L[2]:.2f}, 90th={percentiles_L[3]:.2f}\")\n",
    "\n",
    "    if num_source_plane > 0:\n",
    "        valid_plane_hits = source_plane_hits[np.isfinite(source_plane_hits['y_s']) & np.isfinite(source_plane_hits['z_s'])]\n",
    "        if len(valid_plane_hits) > 0:\n",
    "            r_s = np.sqrt(valid_plane_hits['y_s']**2 + valid_plane_hits['z_s']**2)\n",
    "            print(\"\\n--- Source Plane Hit Statistics ---\")\n",
    "            print(f\"  Planar Radius (r_s) for these hits: min={np.min(r_s):.4f}, max={np.max(r_s):.4f}, mean={np.mean(r_s):.4f}\")\n",
    "            print(f\"  Intersection Time (t_s) for these hits: min={np.min(valid_plane_hits['t_s']):.2f}, max={np.max(valid_plane_hits['t_s']):.2f}, mean={np.mean(valid_plane_hits['t_s']):.2f}\")\n",
    "\n",
    "    if num_sphere > 0:\n",
    "        valid_sphere_hits = sphere_hits[np.isfinite(sphere_hits['final_theta']) & np.isfinite(sphere_hits['final_phi'])]\n",
    "        if len(valid_sphere_hits) > 0:\n",
    "            print(\"\\n--- Celestial Sphere Hit Statistics ---\")\n",
    "            print(f\"  Final Angle (theta) for these hits: min={np.min(valid_sphere_hits['final_theta']):.4f}, max={np.max(valid_sphere_hits['final_theta']):.4f}, mean={np.mean(valid_sphere_hits['final_theta']):.4f}\")\n",
    "            print(f\"  Final Angle (phi)   for these hits: min={np.min(valid_sphere_hits['final_phi']):.4f}, max={np.max(valid_sphere_hits['final_phi']):.4f}, mean={np.mean(valid_sphere_hits['final_phi']):.4f}\")\n",
    "\n",
    "    # --- 4. Generate Expanded Plots (3x2 Grid) ---\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(22, 27))\n",
    "    fig.suptitle(\"Blueprint Data Visualization (Debug-Enabled, Robust Plotting)\", fontsize=20)\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    # Plot 0: Observed Intensity (Stokes I) on Window\n",
    "    if num_disk > 0 and 'valid_disk_hits' in locals() and len(valid_disk_hits) > 0:\n",
    "        plot_data_I = valid_disk_hits[valid_disk_hits['stokes_I'] > 0]\n",
    "        if len(plot_data_I) > 0:\n",
    "            hist = ax[0].hist2d(plot_data_I['y_w'], plot_data_I['z_w'], \n",
    "                                bins=256, cmap='inferno', norm=LogNorm(),\n",
    "                                weights=plot_data_I['stokes_I'])\n",
    "            ax[0].set_title(\"Observed Intensity (Stokes I) on Window Plane\")\n",
    "            ax[0].set_xlabel(\"y_w (M)\"); ax[0].set_ylabel(\"z_w (M)\")\n",
    "            ax[0].set_aspect('equal', 'box')\n",
    "            fig.colorbar(hist[3], ax=ax[0], label=\"Intensity\")\n",
    "        else:\n",
    "            ax[0].text(0.5, 0.5, \"No Positive Intensity Hits\", ha='center', va='center', fontsize=16)\n",
    "            ax[0].set_title(\"Observed Intensity (Stokes I)\")\n",
    "    else:\n",
    "        ax[0].text(0.5, 0.5, \"No Disk Hits\", ha='center', va='center', fontsize=16)\n",
    "        ax[0].set_title(\"Observed Intensity (Stokes I)\")\n",
    "\n",
    "    # Plot 1: Observed Wavelength on Window\n",
    "    if num_disk > 0 and 'valid_disk_hits' in locals() and len(valid_disk_hits) > 0:\n",
    "        if len(valid_disk_hits['lambda_observed']) > 0:\n",
    "            lambda_min = np.min(valid_disk_hits['lambda_observed'])\n",
    "            lambda_max = np.max(valid_disk_hits['lambda_observed'])\n",
    "            if lambda_min >= lambda_max:\n",
    "                lambda_max = lambda_min + 1e-9\n",
    "            \n",
    "            sc = ax[1].scatter(valid_disk_hits['y_w'], valid_disk_hits['z_w'], \n",
    "                               c=valid_disk_hits['lambda_observed'], cmap='jet', s=2, vmin=lambda_min, vmax=lambda_max)\n",
    "            ax[1].set_title(\"Observed Wavelength (λ_obs) on Window Plane\")\n",
    "            ax[1].set_xlabel(\"y_w (M)\"); ax[1].set_ylabel(\"z_w (M)\")\n",
    "            ax[1].set_aspect('equal', 'box')\n",
    "            ax[1].set_facecolor('black')\n",
    "            fig.colorbar(sc, ax=ax[1], label=\"Wavelength (nm)\")\n",
    "        else:\n",
    "            ax[1].text(0.5, 0.5, \"No Valid Wavelength Data\", ha='center', va='center', fontsize=16)\n",
    "            ax[1].set_title(\"Observed Wavelength (λ_obs)\")\n",
    "    else:\n",
    "        ax[1].text(0.5, 0.5, \"No Disk Hits\", ha='center', va='center', fontsize=16)\n",
    "        ax[1].set_title(\"Observed Wavelength (λ_obs)\")\n",
    "\n",
    "    # Plot 2: Observed Wavelength vs. WINDOW Radius\n",
    "    if num_disk > 0 and 'valid_disk_hits' in locals() and len(valid_disk_hits) > 0:\n",
    "        r_w = np.sqrt(valid_disk_hits['y_w']**2 + valid_disk_hits['z_w']**2)\n",
    "        hist2 = ax[2].hist2d(r_w, valid_disk_hits['lambda_observed'], \n",
    "                             bins=(200, 200), cmap='magma', norm=LogNorm())\n",
    "        ax[2].set_title(\"Observed Wavelength vs. Apparent Radius on Window\")\n",
    "        ax[2].set_xlabel(\"Apparent Radius on Window (r_w) [M]\")\n",
    "        ax[2].set_ylabel(\"Observed Wavelength (λ_obs) [nm]\")\n",
    "        fig.colorbar(hist2[3], ax=ax[2], label=\"Number of Rays\")\n",
    "        ax[2].grid(True, linestyle='--', alpha=0.5)\n",
    "    else:\n",
    "        ax[2].text(0.5, 0.5, \"No Disk Hits\", ha='center', va='center', fontsize=16)\n",
    "        ax[2].set_title(\"Observed Wavelength vs. Window Radius\")\n",
    "        \n",
    "    # Plot 3: Intensity Distribution\n",
    "    if num_disk > 0 and 'valid_disk_hits' in locals() and len(valid_disk_hits) > 0:\n",
    "        ax[3].hist(valid_disk_hits['stokes_I'], bins=100, color='cyan', log=True)\n",
    "        ax[3].set_title(\"Distribution of Observed Intensities\")\n",
    "        ax[3].set_xlabel(\"Observed Intensity (Stokes I)\")\n",
    "        ax[3].set_ylabel(\"Number of Rays (Log Scale)\")\n",
    "        ax[3].grid(True, linestyle='--', alpha=0.5)\n",
    "    else:\n",
    "        ax[3].text(0.5, 0.5, \"No Disk Hits\", ha='center', va='center', fontsize=16)\n",
    "        ax[3].set_title(\"Distribution of Observed Intensities\")\n",
    "\n",
    "    # Plot 4: Termination Type Distribution\n",
    "    labels = ['Fail: |p^t| big', 'Disk Hits', 'Source Plane', 'Celestial Sphere', 'Fail: GSL Error', 'Fail: Generic', 'Fail: t_max', 'Fail: Slot Mgr']\n",
    "    sizes = [len(fail_pt_big_hits), num_disk, num_source_plane, num_sphere, len(fail_gsl_hits), len(fail_generic_hits), len(fail_t_max_hits), len(fail_slot_hits)]\n",
    "    colors = ['#2F2F2F', '#FFC300', '#581845', '#C70039', '#FF5733', '#9A9A9A', '#DAF7A6', '#FFC300']\n",
    "    explode_base = (0.1, 0, 0, 0, 0.1, 0.1, 0.1, 0.1)\n",
    "    \n",
    "    plot_labels = [l for i, l in enumerate(labels) if sizes[i] > 0]\n",
    "    plot_sizes = [s for s in sizes if s > 0]\n",
    "    plot_colors = [c for i, c in enumerate(colors) if sizes[i] > 0]\n",
    "    plot_explode = [e for i, e in enumerate(explode_base) if sizes[i] > 0]\n",
    "    \n",
    "    if plot_sizes:\n",
    "        ax[4].pie(plot_sizes, explode=plot_explode, labels=plot_labels, colors=plot_colors,\n",
    "                  autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "        ax[4].set_title(\"Distribution of Ray Termination Types\")\n",
    "        ax[4].axis('equal')\n",
    "    else:\n",
    "        ax[4].text(0.5, 0.5, \"No Data to Plot\", ha='center', va='center', fontsize=16)\n",
    "        ax[4].set_title(\"Distribution of Ray Termination Types\")\n",
    "\n",
    "    # --- UPDATED PLOT 5: Photon Outcome by Window Radius with Failure Breakdown ---\n",
    "    if num_total_rays > 0:\n",
    "        valid_data = data[np.isfinite(data['y_w'])]\n",
    "        r_w = np.sqrt(valid_data['y_w']**2 + valid_data['z_w']**2)\n",
    "        \n",
    "        # Segregate radii by all termination types\n",
    "        r_w_fail_pt   = r_w[valid_data['termination_type'] == 0]\n",
    "        r_w_disk      = r_w[valid_data['termination_type'] == 1]\n",
    "        r_w_source    = r_w[valid_data['termination_type'] == 2]\n",
    "        r_w_sphere    = r_w[valid_data['termination_type'] == 3]\n",
    "        r_w_fail_gsl  = r_w[valid_data['termination_type'] == 5]\n",
    "        r_w_fail_tmax = r_w[valid_data['termination_type'] == 7]\n",
    "        r_w_fail_slot = r_w[valid_data['termination_type'] == 8]\n",
    "        \n",
    "        # Data for the stacked histogram, ordered from bottom to top\n",
    "        x_data = [r_w_fail_gsl, r_w_fail_pt, r_w_disk, r_w_source, r_w_sphere, r_w_fail_tmax, r_w_fail_slot]\n",
    "        \n",
    "        # Labels and colors must match the x_data order\n",
    "        hist_labels = [\n",
    "            f'Fail: GSL Error ({len(r_w_fail_gsl)})',\n",
    "            f'Fail: |p^t| big ({len(r_w_fail_pt)})',\n",
    "            f'DISK ({len(r_w_disk)})',\n",
    "            f'SOURCE ({len(r_w_source)})',\n",
    "            f'SPHERE ({len(r_w_sphere)})',\n",
    "            f'Fail: t_max ({len(r_w_fail_tmax)})',\n",
    "            f'Fail: Slot Mgr ({len(r_w_fail_slot)})'\n",
    "        ]\n",
    "        hist_colors = ['#FF5733', 'black', 'gold', 'purple', 'deepskyblue', '#DAF7A6', '#FFC300']\n",
    "        \n",
    "        # Filter out empty categories to avoid errors in the histogram function\n",
    "        plot_x_data = [d for d in x_data if len(d) > 0]\n",
    "        plot_labels = [l for i, l in enumerate(hist_labels) if len(x_data[i]) > 0]\n",
    "        plot_colors = [c for i, c in enumerate(hist_colors) if len(x_data[i]) > 0]\n",
    "\n",
    "        if plot_x_data:\n",
    "            ax[5].hist(plot_x_data, bins=100, stacked=True, label=plot_labels, color=plot_colors, edgecolor='dimgray')\n",
    "            ax[5].set_title(\"Photon Outcome by Initial Window Radius\")\n",
    "            ax[5].set_xlabel(\"Initial Radial Distance on Window (r_w)\")\n",
    "            ax[5].set_ylabel(\"Number of Photons\")\n",
    "            ax[5].legend()\n",
    "        else:\n",
    "            ax[5].text(0.5, 0.5, \"No Data to Plot\", ha='center', va='center', fontsize=16)\n",
    "            ax[5].set_title(\"Photon Outcome by Initial Window Radius\")\n",
    "\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83cee5",
   "metadata": {},
   "source": [
    "Cell 3 of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cef21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_stacked_radial_histogram(\n",
    "    blueprint_filename: str = \"project/photon_geodesic_integrator/light_blueprint.bin\", \n",
    "    bin_width: float = 0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads the new radiative transfer blueprint file and creates a stacked \n",
    "    histogram showing the outcome of photons as a function of their \n",
    "    initial radial distance on the camera's window plane.\n",
    "\n",
    "    Args:\n",
    "        blueprint_filename: The path to the light_blueprint.bin file.\n",
    "        bin_width: The width of each radial bin for the histogram.\n",
    "    \"\"\"\n",
    "    print(f\"--- Generating stacked radial histogram for '{blueprint_filename}' ---\")\n",
    "    \n",
    "    # --- Load Data ---\n",
    "    if not os.path.exists(blueprint_filename):\n",
    "        print(f\"Error: Blueprint file not found at '{blueprint_filename}'\")\n",
    "        return\n",
    "    \n",
    "    # This function uses the global BLUEPRINT_DTYPE defined in a previous cell.\n",
    "    # It must be executed after the cell that defines BLUEPRINT_DTYPE.\n",
    "    try:\n",
    "        data = np.fromfile(blueprint_filename, dtype=BLUEPRINT_DTYPE)\n",
    "    except NameError:\n",
    "        print(\"ERROR: BLUEPRINT_DTYPE is not defined. Please run the cell that defines it first.\")\n",
    "        return\n",
    "\n",
    "    if len(data) == 0:\n",
    "        print(\"Blueprint file is empty. Cannot generate plot.\")\n",
    "        return\n",
    "        \n",
    "    # --- Calculate r_w for all rays ---\n",
    "    # We must filter out non-finite values that can corrupt statistics\n",
    "    valid_data = data[np.isfinite(data['y_w']) & np.isfinite(data['z_w'])]\n",
    "    r_w = np.sqrt(valid_data['y_w']**2 + valid_data['z_w']**2)\n",
    "    \n",
    "    # --- Separate r_w values based on NEW termination types ---\n",
    "    mask_failure = (valid_data['termination_type'] == 0)\n",
    "    mask_disk    = (valid_data['termination_type'] == 1)\n",
    "    mask_source  = (valid_data['termination_type'] == 2)\n",
    "    mask_sphere  = (valid_data['termination_type'] == 3)\n",
    "    \n",
    "    r_w_failure = r_w[mask_failure]\n",
    "    r_w_disk    = r_w[mask_disk]\n",
    "    r_w_source  = r_w[mask_source]\n",
    "    r_w_sphere  = r_w[mask_sphere]\n",
    "    \n",
    "    # --- Create the Bins for the Histogram ---\n",
    "    if len(r_w) == 0:\n",
    "        print(\"No valid ray data with finite window coordinates found.\")\n",
    "        return\n",
    "    max_radius = r_w.max()\n",
    "    bins = np.arange(0, max_radius + bin_width, bin_width)\n",
    "    \n",
    "    # --- Create the Plot ---\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    \n",
    "    # Data and labels for the stacked histogram\n",
    "    x_data = [r_w_failure, r_w_disk, r_w_source, r_w_sphere]\n",
    "    labels = [\n",
    "        f'FAILURE (Shadow): {len(r_w_failure)}',\n",
    "        f'DISK HIT: {len(r_w_disk)}',\n",
    "        f'SOURCE PLANE: {len(r_w_source)}',\n",
    "        f'SPHERE: {len(r_w_sphere)}'\n",
    "    ]\n",
    "    colors = ['black', 'gold', 'purple', 'deepskyblue']\n",
    "    \n",
    "    # Create the stacked histogram\n",
    "    ax.hist(x_data, bins=bins, stacked=True, label=labels, color=colors, edgecolor='dimgray')\n",
    "    \n",
    "    # --- Add Labels and Title ---\n",
    "    title = f\"Photon Outcome by Initial Radial Distance (Bin Width: {bin_width})\\nTotal Rays: {len(data)}\"\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel('Initial Radial Distance on Window ($r_w$)', fontsize=12)\n",
    "    ax.set_ylabel('Number of Photons (Count)', fontsize=12)\n",
    "    ax.legend(title='Termination Type')\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90def71e",
   "metadata": {},
   "source": [
    "<a id='texture_loader'></a>\n",
    "## 1.f: Image Texture Loading Helper\n",
    "\n",
    "The final rendered image is a composite of multiple sources: the lensed accretion disk, a background star map for rays that escape to infinity, and a fallback texture for rays that hit the geometric source plane.\n",
    "\n",
    "The helper function `_load_texture` is a robust utility for loading these images. It can accept either a file path to an image on disk (e.g., `starmap_2020.png`) or a `numpy` array that has been procedurally generated in memory (like our accretion disk texture). It ensures that the output is always a standardized `numpy` array of floating-point numbers in the range [0.0, 1.0], which is the format required by the rendering functions.\n",
    "\n",
    "### Function: `_load_texture()`\n",
    "*   **Inputs:**\n",
    "    *   `image_input`: A string containing a file path, or a `numpy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a451cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In the cell defining _load_texture\n",
    "\n",
    "def _load_texture(image_input: Union[str, np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Helper function to load an image or use a pre-loaded numpy array,\n",
    "    ensuring the output is always a float64 array with values in [0.0, 1.0].\n",
    "    \"\"\"\n",
    "    if isinstance(image_input, str):\n",
    "        if not os.path.exists(image_input):\n",
    "            raise FileNotFoundError(f\"Texture file not found: {image_input}\")\n",
    "        with Image.open(image_input) as img:\n",
    "            # Convert to RGB and normalize to [0.0, 1.0] floats\n",
    "            return np.array(img.convert(\"RGB\")).astype(np.float64) / 255.0\n",
    "    elif isinstance(image_input, np.ndarray):\n",
    "        # --- CORRECTED LOGIC ---\n",
    "        # 1. Ensure the array is float64 for calculations.\n",
    "        texture_array = image_input.astype(np.float64)\n",
    "        # 2. Check if the values are in the [0, 255] range. If so, normalize them.\n",
    "        if np.max(texture_array) > 1.0:\n",
    "            texture_array /= 255.0\n",
    "        return texture_array\n",
    "    else:\n",
    "        raise TypeError(\"Image input must be a file path (str) or a NumPy array.\")\n",
    "\n",
    "print(\"Helper function `_load_texture` (Corrected) defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0784077",
   "metadata": {},
   "source": [
    "<a id='disk_generator'></a>\n",
    "## 1.g: Procedural Accretion Disk Generators\n",
    "\n",
    "Instead of using a static image file for the accretion disk, we can generate it procedurally. This gives us full control over its appearance and physical properties. The following cells define two functions for this purpose.\n",
    "\n",
    "### Function: `generate_source_disk_array()`\n",
    "This function generates a simple, physically motivated accretion disk. It creates a 2D image where the brightness (temperature) of the disk follows a power law, $T \\propto r^p$, and is confined between an inner and outer radius. It also includes a smooth falloff at the edges to produce a more realistic, anti-aliased appearance.\n",
    "\n",
    "*   **Key Inputs:**\n",
    "    *   `pixel_width`: The resolution of the output image array.\n",
    "    *   `disk_physical_width`: The total size of the image in physical units (M).\n",
    "    *   `disk_inner_radius`, `disk_outer_radius`: The boundaries of the luminous part of the disk.\n",
    "    *   `disk_temp_power_law`: The exponent `p` for the temperature profile.\n",
    "\n",
    "### Function: `generate_advanced_disk_array()`\n",
    "This function generates a more complex, EHT-style disk with additional features for greater realism and visual interest. It builds upon the simple power-law model by adding:\n",
    "*   **Concentric Rings**: Simulates gaps or brighter rings in the disk.\n",
    "*   **Doppler Beaming**: Creates an asymmetry in brightness, making the side of the disk moving towards the observer appear brighter, consistent with relativistic effects.\n",
    "*   **Hotspots and Lobes**: Allows for the addition of localized bright spots or large-scale structural variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edcaa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for Visualizing/Generating the Unlensed Source Disk (UPDATED with Anti-Aliasing)\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_source_disk_array(\n",
    "    pixel_width=512,\n",
    "    disk_physical_width=40.0,\n",
    "    disk_inner_radius=6.0,\n",
    "    disk_outer_radius=20.0,\n",
    "    disk_temp_power_law=-0.75,\n",
    "    colormap='hot',\n",
    "    display_image=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates an anti-aliased NumPy array of an accretion disk image.\n",
    "    \"\"\"\n",
    "    # --- 1. Create a Coordinate Grid ---\n",
    "    half_width = disk_physical_width / 2.0\n",
    "    y_coords = np.linspace(-half_width, half_width, pixel_width)\n",
    "    z_coords = np.linspace(-half_width, half_width, pixel_width)\n",
    "    yy, zz = np.meshgrid(y_coords, z_coords)\n",
    "\n",
    "    # --- 2. Calculate Physical Properties for Each Pixel ---\n",
    "    radii = np.sqrt(yy**2 + zz**2)\n",
    "\n",
    "    # --- 3. Apply the Disk Model with a Smooth Falloff ---\n",
    "    # Instead of a sharp mask, we'll calculate temperature for all points\n",
    "    # and then smoothly fade it to zero outside the disk bounds.\n",
    "    \n",
    "    # Calculate temperature based on the power law everywhere.\n",
    "    # Add a small epsilon to radii to avoid division by zero at the center.\n",
    "    temperature = (radii / disk_inner_radius)**disk_temp_power_law\n",
    "\n",
    "    # Create a smooth falloff mask using numpy.clip\n",
    "    # This will create a smooth transition from 1 (inside the disk) to 0 (outside)\n",
    "    # over a small number of pixels. Let's define a transition width.\n",
    "    transition_width = 2.0 * (disk_physical_width / pixel_width) # Width of 2 pixels\n",
    "\n",
    "    # Inner edge falloff\n",
    "    inner_falloff = np.clip((radii - (disk_inner_radius - transition_width)) / transition_width, 0, 1)\n",
    "    \n",
    "    # Outer edge falloff\n",
    "    outer_falloff = 1.0 - np.clip((radii - disk_outer_radius) / transition_width, 0, 1)\n",
    "\n",
    "    # Combine the masks and apply to the temperature\n",
    "    smooth_mask = inner_falloff * outer_falloff\n",
    "    temperature *= smooth_mask\n",
    "\n",
    "    # --- 4. Map Temperature to Color and Create Image Array ---\n",
    "    colormap_func = plt.colormaps[colormap]\n",
    "    colors = colormap_func(temperature / np.max(temperature)) # Normalize to ensure max is 1\n",
    "    image_array = (colors[:, :, :3] * 255).astype(np.uint8)\n",
    "    \n",
    "    # --- 5. Optionally Display the Image ---\n",
    "    if display_image:\n",
    "        print(f\"Displaying the unlensed source disk (with anti-aliasing):\")\n",
    "        img = Image.fromarray(image_array)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Unlensed Source Accretion Disk (Anti-Aliased)\")\n",
    "        plt.show()\n",
    "        \n",
    "    # --- 6. Return the NumPy array ---\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f126c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In the cell defining generate_advanced_disk_array\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_advanced_disk_array(\n",
    "    # --- Basic Settings ---\n",
    "    pixel_width=1024,\n",
    "    disk_physical_width=30.0,\n",
    "    colormap='afmhot',\n",
    "    \n",
    "    # --- Base Radial Profile ---\n",
    "    disk_inner_radius=6.0,\n",
    "    disk_outer_radius=25.0,\n",
    "    disk_temp_power_law=-2.0,\n",
    "    \n",
    "    # --- Concentric Rings / Gaps ---\n",
    "    ring_num=5,\n",
    "    ring_contrast=0.7,\n",
    "    ring_log_spacing=True,\n",
    "    \n",
    "    # --- Doppler Beaming (Asymmetric Brightness) ---\n",
    "    doppler_factor=0.8,\n",
    "    doppler_power=3,\n",
    "    \n",
    "    # --- Optional Features (set to 0 to disable) ---\n",
    "    hotspot_num=0,\n",
    "    hotspot_amplitude=0.15,\n",
    "    hotspot_radius_center=9.0,\n",
    "    hotspot_radius_width=3.0,\n",
    "    shape_num_lobes=0,\n",
    "    shape_inner_amplitude=0.0,\n",
    "    shape_outer_amplitude=0.0,\n",
    "    \n",
    "    # --- Display Control ---\n",
    "    display_image=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates an EHT-style disk, combining advanced features with robust NaN handling.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating EHT-Style Accretion Disk Texture (Corrected v3) ---\")\n",
    "    \n",
    "    # 1. Create Coordinate Grid & Polar Coordinates\n",
    "    half_width = disk_physical_width / 2.0\n",
    "    y_coords = np.linspace(-half_width, half_width, pixel_width)\n",
    "    z_coords = np.linspace(-half_width, half_width, pixel_width)\n",
    "    yy, zz = np.meshgrid(y_coords, z_coords)\n",
    "    radii = np.sqrt(yy**2 + zz**2)\n",
    "    phi = np.arctan2(zz, yy)\n",
    "\n",
    "    # 2. Calculate Base Temperature\n",
    "    # Add a small epsilon to radii to avoid division by zero at the center.\n",
    "    temperature = (radii / (disk_inner_radius + 1e-12))**disk_temp_power_law\n",
    "    \n",
    "    # --- CORRECTED: Explicitly handle the NaN at the center ---\n",
    "    # This is the crucial fix from the older, working code.\n",
    "    temperature[np.isnan(temperature)] = 0\n",
    "\n",
    "    # 3. Apply Modulations (Rings, Doppler, etc.)\n",
    "    if ring_num > 0:\n",
    "        if ring_log_spacing:\n",
    "            radial_coord = np.log(radii / disk_inner_radius + 1e-9)\n",
    "            max_log_rad = np.log(disk_outer_radius / disk_inner_radius)\n",
    "            ring_mod = 0.5 * (1 + np.cos(ring_num * 2 * np.pi * radial_coord / max_log_rad))\n",
    "        else:\n",
    "            radial_coord = radii\n",
    "            ring_mod = 0.5 * (1 + np.cos(ring_num * 2 * np.pi * (radial_coord - disk_inner_radius) / (disk_outer_radius - disk_inner_radius)))\n",
    "        ring_mod = 1.0 - ring_contrast * (1.0 - ring_mod)\n",
    "        temperature *= ring_mod\n",
    "\n",
    "    if doppler_factor > 0:\n",
    "        doppler_mod = (1 + doppler_factor * (-np.cos(phi)))**doppler_power\n",
    "        temperature *= doppler_mod\n",
    "        \n",
    "    # ... (hotspot logic would go here) ...\n",
    "\n",
    "    # 4. Apply Final Radial Mask\n",
    "    # This uses the smooth falloff logic from the older, working code.\n",
    "    transition_width = 2.0 * (disk_physical_width / pixel_width)\n",
    "    r_inner_mod = disk_inner_radius + shape_inner_amplitude * np.cos(shape_num_lobes * phi)\n",
    "    r_outer_mod = disk_outer_radius + shape_outer_amplitude * np.cos(shape_num_lobes * phi)\n",
    "    inner_falloff = np.clip((radii - (r_inner_mod - transition_width)) / transition_width, 0, 1)\n",
    "    outer_falloff = 1.0 - np.clip((radii - r_outer_mod) / transition_width, 0, 1)\n",
    "    smooth_mask = inner_falloff * outer_falloff\n",
    "    temperature *= smooth_mask\n",
    "\n",
    "    # 5. Map to Color using robust normalization\n",
    "    max_temp = np.max(temperature)\n",
    "    if max_temp > 0:\n",
    "        norm_temperature = temperature / max_temp\n",
    "    else:\n",
    "        norm_temperature = temperature # Avoid division by zero if all temps are zero\n",
    "\n",
    "    colormap_func = plt.colormaps[colormap]\n",
    "    colors = colormap_func(norm_temperature)\n",
    "    image_array = (colors[:, :, :3] * 255).astype(np.uint8)\n",
    "    \n",
    "    # 6. Display\n",
    "    if display_image:\n",
    "        print(\"Displaying the unlensed advanced source disk:\")\n",
    "        img = Image.fromarray(image_array)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(img, extent=[-half_width, half_width, -half_width, half_width])\n",
    "        plt.title(\"Advanced, EHT-Style Source Disk (Corrected)\")\n",
    "        plt.xlabel(\"y (M)\")\n",
    "        plt.ylabel(\"z (M)\")\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.show()\n",
    "        \n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae1e9be",
   "metadata": {},
   "source": [
    "<a id='static_renderer'></a>\n",
    "## 1.h: Static Lensed Image Renderer\n",
    "\n",
    "This is the core rendering engine. The function `generate_static_lensed_image` takes the raw `light_blueprint.bin` data and all the necessary texture maps (for the disk, celestial sphere, etc.) and assembles the final, lensed image.\n",
    "\n",
    "The process is as follows:\n",
    "1.  **Load Blueprint**: It reads the entire blueprint file into a `numpy` structured array.\n",
    "2.  **Process Rays**: It iterates through each ray in the blueprint. Based on the ray's `termination_type`, it determines what the camera \"saw.\"\n",
    "    *   If it hit the **disk**, it uses the observed intensity and wavelength to calculate a final color.\n",
    "    *   If it hit the **source plane** or **celestial sphere**, it uses the calculated `(y_s, z_s)` or `(θ, φ)` coordinates to look up the corresponding color from the source or sphere texture maps.\n",
    "    *   If it **failed** (hit the black hole shadow), the pixel is left black.\n",
    "3.  **Tone Mapping**: The light from an accretion disk has a very high dynamic range (the difference between the brightest and dimmest parts is huge). To make this visible on a standard screen, the function applies a non-linear **gamma correction** (a form of tone mapping) only to the light from the disk. This compresses the dynamic range, making both the bright inner regions and the dimmer outer regions visible.\n",
    "4.  **Composite Image**: It additively blends the tone-mapped disk layer with the linear background layers (source plane and celestial sphere) to create the final composite image.\n",
    "5.  **Save Image**: The final `numpy` array is converted to an image file (e.g., PNG) and saved to disk.\n",
    "\n",
    "### Function: `generate_static_lensed_image()`\n",
    "*   **Key Inputs:**\n",
    "    *   `output_filename`: The path to save the final image.\n",
    "    *   `blueprint_filename`: The path to the input `light_blueprint.bin` file.\n",
    "    *   `source_image`, `sphere_image`: The texture maps to use for the source and celestial sphere.\n",
    "    *   `intensity_scale`, `gamma`: Parameters to control the brightness and contrast of the final image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1444301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_static_lensed_image(\n",
    "    output_filename: str,\n",
    "    output_pixel_width: int,\n",
    "    source_image_width: float,\n",
    "    sphere_image: Union[str, np.ndarray],\n",
    "    source_image: Union[str, np.ndarray],\n",
    "    intensity_scale: float = 1.0,\n",
    "    lambda_min_nm: Optional[float] = None,\n",
    "    lambda_max_nm: Optional[float] = None,\n",
    "    gamma: float = 2.2,\n",
    "    blueprint_filename: str = \"project/photon_geodesic_integrator/light_blueprint.bin\",\n",
    "    window_width: Optional[float] = None,\n",
    "    zoom_region: Optional[Union[List[float], Tuple[float, float, float, float]]] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generates a lensed image using a multi-layer composite with selective tone mapping.\n",
    "    \n",
    "    This definitive version applies non-linear gamma correction only to the\n",
    "    high-dynamic-range disk light, preserving the linear color of background\n",
    "    sources, and then additively blends them for a physically realistic image.\n",
    "    \"\"\"\n",
    "    print(f\"--- Generating Static Lensed Image (Selective Tone Mapping): '{output_filename}' ---\")\n",
    "    \n",
    "    # --- Phase 1: Initialization and Data Loading ---\n",
    "    if not os.path.exists(blueprint_filename):\n",
    "        raise FileNotFoundError(f\"Blueprint file not found: {blueprint_filename}\")\n",
    "    blueprint_data = np.fromfile(blueprint_filename, dtype=BLUEPRINT_DTYPE)\n",
    "    if zoom_region:\n",
    "        y_w_min, y_w_max, z_w_min, z_w_max = zoom_region\n",
    "    elif window_width:\n",
    "        half_w = window_width / 2.0\n",
    "        y_w_min, y_w_max = -half_w, half_w\n",
    "        z_w_min, z_w_max = -half_w, half_w\n",
    "    else:\n",
    "        raise ValueError(\"Either 'window_width' or 'zoom_region' must be provided.\")\n",
    "    window_y_range = y_w_max - y_w_min\n",
    "    window_z_range = z_w_max - z_w_min\n",
    "    aspect_ratio = window_z_range / window_y_range\n",
    "    output_pixel_height = int(output_pixel_width * aspect_ratio)\n",
    "    source_texture = _load_texture(source_image)\n",
    "    sphere_texture = _load_texture(sphere_image)\n",
    "\n",
    "    # Separate accumulators for disk (foreground) and other (background) layers\n",
    "    disk_pixel_accumulator = np.zeros((output_pixel_height, output_pixel_width, 3), dtype=np.float64)\n",
    "    background_pixel_accumulator = np.zeros((output_pixel_height, output_pixel_width, 3), dtype=np.float64)\n",
    "    # A single counter for all successful rays per pixel\n",
    "    count_accumulator = np.zeros((output_pixel_height, output_pixel_width), dtype=np.int32)\n",
    "\n",
    "    # --- Phase 2: Vectorized Ray Processing ---\n",
    "    mask_in_view = (\n",
    "        (blueprint_data['y_w'] >= y_w_min) & (blueprint_data['y_w'] < y_w_max) &\n",
    "        (blueprint_data['z_w'] >= z_w_min) & (blueprint_data['z_w'] < z_w_max)\n",
    "    )\n",
    "    rays_in_view = blueprint_data[mask_in_view]\n",
    "    \n",
    "    if len(rays_in_view) > 0:\n",
    "        px_float = (rays_in_view['y_w'] - y_w_min) / window_y_range * output_pixel_width\n",
    "        py_float = (z_w_max - rays_in_view['z_w']) / window_z_range * output_pixel_height\n",
    "        px = np.clip(px_float, 0, output_pixel_width - 1).astype(np.int32)\n",
    "        py = np.clip(py_float, 0, output_pixel_height - 1).astype(np.int32)\n",
    "\n",
    "        # --- Process each termination type into its correct layer ---\n",
    "        \n",
    "        # 1. DISK HITS -> Disk Layer\n",
    "        is_disk = rays_in_view['termination_type'] == 1\n",
    "        if np.any(is_disk):\n",
    "            disk_hits = rays_in_view[is_disk]\n",
    "            valid_disk_hits = disk_hits[np.isfinite(disk_hits['lambda_observed'])]\n",
    "            if len(valid_disk_hits) > 0:\n",
    "                lambda_min = lambda_min_nm if lambda_min_nm is not None else np.min(valid_disk_hits['lambda_observed'])\n",
    "                lambda_max = lambda_max_nm if lambda_max_nm is not None else np.max(valid_disk_hits['lambda_observed'])\n",
    "                base_colors = wavelength_to_rgb(disk_hits['lambda_observed'], min_vis_wl=lambda_min, max_vis_wl=lambda_max)\n",
    "                intensities = disk_hits['stokes_I'][:, np.newaxis]\n",
    "                disk_colors = base_colors * intensities * intensity_scale\n",
    "                np.add.at(disk_pixel_accumulator, (py[is_disk], px[is_disk]), disk_colors)\n",
    "\n",
    "        # 2. SOURCE PLANE HITS -> Background Layer\n",
    "        is_source_plane = rays_in_view['termination_type'] == 2\n",
    "        if np.any(is_source_plane):\n",
    "            source_plane_hits = rays_in_view[is_source_plane]\n",
    "            source_pixel_height, source_pixel_width, _ = source_texture.shape\n",
    "            half_sw = source_image_width / 2.0\n",
    "            norm_y = (source_plane_hits['y_s'] + half_sw) / source_image_width\n",
    "            norm_z = (source_plane_hits['z_s'] + half_sw) / source_image_width\n",
    "            px_s = norm_y * (source_pixel_width - 1)\n",
    "            py_s = (1.0 - norm_z) * (source_pixel_height - 1)\n",
    "            px_s_int = np.clip(px_s, 0, source_pixel_width - 1).astype(np.int32)\n",
    "            py_s_int = np.clip(py_s, 0, source_pixel_height - 1).astype(np.int32)\n",
    "            source_colors = source_texture[py_s_int, px_s_int]\n",
    "            np.add.at(background_pixel_accumulator, (py[is_source_plane], px[is_source_plane]), source_colors)\n",
    "\n",
    "        # 3. CELESTIAL SPHERE HITS -> Background Layer\n",
    "        is_sphere = rays_in_view['termination_type'] == 3\n",
    "        if np.any(is_sphere):\n",
    "            sphere_hits = rays_in_view[is_sphere]\n",
    "            sphere_pixel_height, sphere_pixel_width, _ = sphere_texture.shape\n",
    "            norm_phi = (sphere_hits['final_phi'] + np.pi) / (2 * np.pi)\n",
    "            norm_theta = sphere_hits['final_theta'] / np.pi\n",
    "            px_sph = norm_phi * (sphere_pixel_width - 1)\n",
    "            py_sph = norm_theta * (sphere_pixel_height - 1)\n",
    "            px_sph_int = np.clip(px_sph, 0, sphere_pixel_width - 1).astype(np.int32)\n",
    "            py_sph_int = np.clip(py_sph, 0, sphere_pixel_height - 1).astype(np.int32)\n",
    "            sphere_colors = sphere_texture[py_sph_int, px_sph_int]\n",
    "            np.add.at(background_pixel_accumulator, (py[is_sphere], px[is_sphere]), sphere_colors)\n",
    "\n",
    "        # Increment the count for every ray that successfully terminated\n",
    "        np.add.at(count_accumulator, (py, px), 1)\n",
    "\n",
    "    # --- Phase 3: Assembling Final Image with Selective Tone Mapping ---\n",
    "    hit_pixels_mask = count_accumulator > 0\n",
    "    \n",
    "    # 1. Calculate the average color for each layer separately\n",
    "    avg_disk_color = np.zeros_like(disk_pixel_accumulator)\n",
    "    avg_background_color = np.zeros_like(background_pixel_accumulator)\n",
    "    \n",
    "    # Use the mask to avoid division by zero for pixels that were not hit\n",
    "    avg_disk_color[hit_pixels_mask] = disk_pixel_accumulator[hit_pixels_mask] / count_accumulator[hit_pixels_mask, np.newaxis]\n",
    "    avg_background_color[hit_pixels_mask] = background_pixel_accumulator[hit_pixels_mask] / count_accumulator[hit_pixels_mask, np.newaxis]\n",
    "\n",
    "    # 2. Apply Tone Mapping ONLY to the averaged disk layer\n",
    "    tone_mapped_disk_color = np.zeros_like(avg_disk_color)\n",
    "    disk_hit_mask = np.any(avg_disk_color > 0, axis=2) # Find pixels that actually have disk light\n",
    "    \n",
    "    # --- THIS IS THE CORRECTED BLOCK ---\n",
    "    # Only perform normalization and gamma if there were actual disk hits.\n",
    "    if np.any(disk_hit_mask):\n",
    "        max_disk_brightness = np.max(avg_disk_color[disk_hit_mask])\n",
    "        normalized_disk_color = avg_disk_color[disk_hit_mask]\n",
    "        if max_disk_brightness > 0:\n",
    "            normalized_disk_color /= max_disk_brightness\n",
    "            \n",
    "        scaled_disk_color = normalized_disk_color * intensity_scale\n",
    "        \n",
    "        tone_mapped_disk_color[disk_hit_mask] = scaled_disk_color ** (1.0 / gamma)\n",
    "    # --- END OF CORRECTION ---\n",
    "        \n",
    "    \n",
    "    # 3. Additively blend the tone-mapped disk with the linear background\n",
    "    final_image_float = tone_mapped_disk_color + avg_background_color\n",
    "        \n",
    "    # 4. Convert to final image format\n",
    "    final_image_uint8 = (np.clip(final_image_float, 0, 1) * 255).astype(np.uint8)\n",
    "    img = Image.fromarray(final_image_uint8, 'RGB')\n",
    "    \n",
    "    output_dir = os.path.dirname(output_filename)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    img.save(output_filename)\n",
    "    print(f\"--- Static image saved to '{output_filename}' ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b84dba",
   "metadata": {},
   "source": [
    "<a id='animated_renderer'></a>\n",
    "## 1.i: Animated Lensed Image Renderer\n",
    "\n",
    "This function, `generate_animated_lensed_image`, extends the static renderer to create a single frame of an animation. The key difference is that it accounts for the **light-travel time** and the **differential rotation** of the accretion disk.\n",
    "\n",
    "When an observer sees light from different parts of the disk simultaneously, that light was actually emitted at different times in the past, because it took longer for light from the far side of the disk to reach the camera than light from the near side. The `t_s` value in our blueprint file stores this light-travel time for each ray.\n",
    "\n",
    "This function uses this information to correctly render a snapshot of a dynamic, rotating disk. For a given animation time `t_anim`, the total time at which a fluid element emitted the light we see is `t_total = t_anim + t_s`. The function calculates the Keplerian orbital period for each point on the disk ($T \\propto r^{3/2}$) and uses `t_total` to rotate that point to its correct position at the moment of emission. It then looks up the color from the source texture at this *rotated* position. This process, repeated for every frame, creates the illusion of a dynamic, swirling accretion disk.\n",
    "\n",
    "### Function: `generate_animated_lensed_image()`\n",
    "*   **Key Inputs:**\n",
    "    *   `t_anim`: The current time of the animation frame being rendered.\n",
    "    *   `M_scale`: The mass of the black hole, needed to calculate the Keplerian orbital period.\n",
    "    *   All other inputs are similar to the static renderer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572a410",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_animated_lensed_image(\n",
    "    output_filename: str,\n",
    "    output_pixel_width: int,\n",
    "    source_image_width: float,\n",
    "    sphere_image: Union[str, np.ndarray],\n",
    "    source_image: Union[str, np.ndarray],\n",
    "    # --- Parameters for orbital dynamics ---\n",
    "    M_scale: float,\n",
    "    t_anim: float,\n",
    "    prograde_disk: bool = True,\n",
    "    # ---\n",
    "    blueprint_filename: str = \"project/photon_geodesic_integrator/blueprint.bin\",\n",
    "    window_width: Optional[float] = None,\n",
    "    zoom_region: Optional[Union[List[float], Tuple[float, float, float, float]]] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generates a lensed image of a DYNAMIC, differentially rotating Keplerian disk.\n",
    "    \n",
    "    This version uses the animation time (t_anim) and light-travel time (t_s)\n",
    "    to calculate the rotational position of the disk at the moment of emission.\n",
    "    \"\"\"\n",
    "    # The body of this function is identical to the one I provided previously,\n",
    "    # as its logic for handling animation was already correct.\n",
    "    \n",
    "    # --- Phase 1: Initialization and Setup ---\n",
    "    if zoom_region:\n",
    "        y_w_min, y_w_max, z_w_min, z_w_max = zoom_region\n",
    "    elif window_width:\n",
    "        half_w = window_width / 2.0\n",
    "        y_w_min, y_w_max = -half_w, half_w\n",
    "        z_w_min, z_w_max = -half_w, half_w\n",
    "    else:\n",
    "        raise ValueError(\"Either 'window_width' or 'zoom_region' must be provided.\")\n",
    "\n",
    "    window_y_range = y_w_max - y_w_min\n",
    "    window_z_range = z_w_max - z_w_min\n",
    "    aspect_ratio = window_z_range / window_y_range\n",
    "    output_pixel_height = int(output_pixel_width * aspect_ratio)\n",
    "\n",
    "    source_texture = _load_texture(source_image)\n",
    "    sphere_texture = _load_texture(sphere_image)\n",
    "    source_pixel_height, source_pixel_width, _ = source_texture.shape\n",
    "    sphere_pixel_height, sphere_pixel_width, _ = sphere_texture.shape\n",
    "\n",
    "    if not os.path.exists(blueprint_filename):\n",
    "        raise FileNotFoundError(f\"Blueprint file not found: {blueprint_filename}\")\n",
    "    blueprint_data = np.fromfile(blueprint_filename, dtype=BLUEPRINT_DTYPE)\n",
    "\n",
    "    pixel_accumulator = np.zeros((output_pixel_height, output_pixel_width, 3), dtype=np.float64)\n",
    "    count_accumulator = np.zeros((output_pixel_height, output_pixel_width), dtype=np.int32)\n",
    "\n",
    "    # --- Phase 2: Vectorized Ray Processing ---\n",
    "    mask_in_view = (\n",
    "        (blueprint_data['y_w'] >= y_w_min) & (blueprint_data['y_w'] < y_w_max) &\n",
    "        (blueprint_data['z_w'] >= z_w_min) & (blueprint_data['z_w'] < z_w_max)\n",
    "    )\n",
    "    rays_in_view = blueprint_data[mask_in_view]\n",
    "    \n",
    "    if len(rays_in_view) > 0:\n",
    "        px_float = (rays_in_view['y_w'] - y_w_min) / window_y_range * output_pixel_width\n",
    "        py_float = (z_w_max - rays_in_view['z_w']) / window_z_range * output_pixel_height\n",
    "        px = np.clip(px_float, 0, output_pixel_width - 1).astype(np.int32)\n",
    "        py = np.clip(py_float, 0, output_pixel_height - 1).astype(np.int32)\n",
    "\n",
    "        is_source = rays_in_view['termination_type'] == 1\n",
    "        is_sphere = rays_in_view['termination_type'] == 2\n",
    "\n",
    "        if np.any(is_source):\n",
    "            source_hits = rays_in_view[is_source]\n",
    "            \n",
    "            y_s_intersect = source_hits['y_s']\n",
    "            z_s_intersect = source_hits['z_s']\n",
    "            t_s = source_hits['t_s']\n",
    "            \n",
    "            r_s = np.sqrt(y_s_intersect**2 + z_s_intersect**2)\n",
    "            Omega = np.sqrt(M_scale / (r_s**3 + 1e-12))\n",
    "            \n",
    "            total_time = t_anim + t_s\n",
    "            rotation_angle = Omega * total_time\n",
    "            rotation_direction = -1.0 if prograde_disk else 1.0\n",
    "            final_angle = rotation_direction * rotation_angle\n",
    "            \n",
    "            cos_angle = np.cos(final_angle)\n",
    "            sin_angle = np.sin(final_angle)\n",
    "            \n",
    "            y_s_emit = y_s_intersect * cos_angle - z_s_intersect * sin_angle\n",
    "            z_s_emit = y_s_intersect * sin_angle + z_s_intersect * cos_angle\n",
    "            \n",
    "            half_sw = source_image_width / 2.0\n",
    "            norm_y = (y_s_emit + half_sw) / source_image_width\n",
    "            norm_z = (z_s_emit + half_sw) / source_image_width\n",
    "\n",
    "            px_s = norm_y * (source_pixel_width - 1)\n",
    "            py_s = (1.0 - norm_z) * (source_pixel_height - 1)\n",
    "            px_s_int = np.clip(px_s, 0, source_pixel_width - 1).astype(np.int32)\n",
    "            py_s_int = np.clip(py_s, 0, source_pixel_height - 1).astype(np.int32)\n",
    "            source_colors = source_texture[py_s_int, px_s_int]\n",
    "            np.add.at(pixel_accumulator, (py[is_source], px[is_source]), source_colors)\n",
    "\n",
    "        if np.any(is_sphere):\n",
    "            sphere_hits = rays_in_view[is_sphere]\n",
    "            norm_phi = (sphere_hits['final_phi'] + np.pi) / (2 * np.pi)\n",
    "            norm_theta = sphere_hits['final_theta'] / np.pi\n",
    "            px_sph = norm_phi * (sphere_pixel_width - 1)\n",
    "            py_sph = norm_theta * (sphere_pixel_height - 1)\n",
    "            px_sph_int = np.clip(px_sph, 0, sphere_pixel_width - 1).astype(np.int32)\n",
    "            py_sph_int = np.clip(py_sph, 0, sphere_pixel_height - 1).astype(np.int32)\n",
    "            sphere_colors = sphere_texture[py_sph_int, px_sph_int]\n",
    "            np.add.at(pixel_accumulator, (py[is_sphere], px[is_sphere]), sphere_colors)\n",
    "\n",
    "        np.add.at(count_accumulator, (py, px), 1)\n",
    "\n",
    "    # --- Phase 3: Assembling Final Image ---\n",
    "    hit_pixels_mask = count_accumulator > 0\n",
    "    final_image_float = np.zeros_like(pixel_accumulator)\n",
    "    final_image_float[hit_pixels_mask] = (\n",
    "        pixel_accumulator[hit_pixels_mask] / count_accumulator[hit_pixels_mask, np.newaxis]\n",
    "    )\n",
    "    \n",
    "    final_image_uint8 = (np.clip(final_image_float, 0, 1) * 255).astype(np.uint8)\n",
    "    \n",
    "    img = Image.fromarray(final_image_uint8, 'RGB')\n",
    "    \n",
    "    output_dir = os.path.dirname(output_filename)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    img.save(output_filename)\n",
    "    print(f\"--- Animated frame saved to '{output_filename}' ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2cab0",
   "metadata": {},
   "source": [
    "<a id='animation_orchestrator'></a>\n",
    "## 1.j: Master Animation Frame Generator\n",
    "\n",
    "This function, `generate_animation_frames`, is the top-level orchestrator for creating an entire animation sequence. It does not perform any rendering itself; instead, it manages the process of generating a series of frames.\n",
    "\n",
    "Its logic is as follows:\n",
    "1.  **Calculate Animation Timeline**: It takes the desired number of frames and the number of orbits the disk should complete at its fastest point (the ISCO) and calculates the total physical time duration of the animation.\n",
    "2.  **Master Loop**: It enters a loop that iterates from the first frame to the last.\n",
    "3.  **Call Renderer**: Inside the loop, for each frame, it calculates the corresponding animation time `t_anim` and calls the `generate_animated_lensed_image` function to render that single frame.\n",
    "4.  **Save Frame**: Each rendered frame is saved to disk with a sequential filename (e.g., `frame_0000.png`, `frame_0001.png`, etc.).\n",
    "\n",
    "After this function completes, the output folder will contain all the individual PNG images needed to create the final video.\n",
    "\n",
    "### Function: `generate_animation_frames()`\n",
    "*   **Key Inputs:**\n",
    "    *   `num_frames`: The total number of frames to generate.\n",
    "    *   `orbits_at_isco`: Controls the speed of the animation.\n",
    "    *   `output_folder`: The directory where the final PNG frames will be saved.\n",
    "    *   All other inputs are passed down to the per-frame renderer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a21ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import display, Image as IPImage\n",
    "from typing import Union\n",
    "\n",
    "def generate_animation_frames(\n",
    "    # --- Core Inputs ---\n",
    "    blueprint_filename: str,\n",
    "    output_folder: str,\n",
    "    \n",
    "    # --- Rendering & Physics Parameters ---\n",
    "    source_texture: Union[str, np.ndarray],\n",
    "    sphere_texture: Union[str, np.ndarray],\n",
    "    source_physical_width: float,\n",
    "    mass_of_black_hole: float,\n",
    "    \n",
    "    # --- Animation Control ---\n",
    "    num_frames: int = 120,\n",
    "    orbits_at_isco: float = 2.0,\n",
    "    is_prograde: bool = True,\n",
    "    \n",
    "    # --- Image & Window Settings ---\n",
    "    output_pixel_width: int = 400,\n",
    "    window_width: float = 1.5\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generates a sequence of lensed image frames for creating an animation.\n",
    "\n",
    "    This function takes a single ray-tracing blueprint and generates multiple\n",
    "    frames by animating a differentially rotating Keplerian disk over time.\n",
    "\n",
    "    Args:\n",
    "        blueprint_filename: Path to the input 'blueprint.bin' file.\n",
    "        output_folder: Directory where the output frames will be saved.\n",
    "        source_texture: Path to the source image or a pre-loaded NumPy array.\n",
    "        sphere_texture: Path to the background star map or a pre-loaded NumPy array.\n",
    "        source_physical_width: The physical width (in units of M) of the source texture.\n",
    "        mass_of_black_hole: The mass (M_scale) of the black hole.\n",
    "        num_frames: The total number of frames to generate for the animation.\n",
    "        orbits_at_isco: The total number of orbits the disk completes at the ISCO (r=6M)\n",
    "                        over the full animation duration.\n",
    "        is_prograde: Direction of disk rotation (True for prograde, False for retrograde).\n",
    "        output_pixel_width: The width of the output images in pixels.\n",
    "        window_width: The physical width of the camera's viewing window.\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting Animation Generation ---\")\n",
    "    \n",
    "    # --- Setup and Validation ---\n",
    "    if not os.path.exists(blueprint_filename):\n",
    "        raise FileNotFoundError(f\"Blueprint file not found: {blueprint_filename}\")\n",
    "        \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Calculate total animation time based on the desired number of orbits at the ISCO\n",
    "    # ISCO for Schwarzschild is at r=6M.\n",
    "    isco_radius = 6.0 \n",
    "    orbital_period_at_isco = 2 * np.pi * np.sqrt(isco_radius**3 / mass_of_black_hole)\n",
    "    total_animation_time = orbital_period_at_isco * orbits_at_isco\n",
    "    \n",
    "    print(f\"  Configuration:\")\n",
    "    print(f\"    Total frames: {num_frames}\")\n",
    "    print(f\"    Total animation time: {total_animation_time:.2f} M ({orbits_at_isco:.1f} orbits at r=6M)\")\n",
    "    print(f\"    Output folder: '{output_folder}'\")\n",
    "\n",
    "    # --- Master Animation Loop ---\n",
    "    for i in range(num_frames):\n",
    "        # Calculate the animation time for the current frame\n",
    "        t_animation = (i / (num_frames - 1)) * total_animation_time if num_frames > 1 else 0\n",
    "        \n",
    "        # Define a sequential filename for the frame\n",
    "        frame_filename = os.path.join(output_folder, f\"frame_{i:04d}.png\")\n",
    "        \n",
    "        print(f\"Rendering frame {i+1}/{num_frames} (t_anim = {t_animation:.2f} M)...\")\n",
    "        \n",
    "        # Call the rendering function for a single frame\n",
    "        generate_animated_lensed_image(\n",
    "            output_filename=frame_filename,\n",
    "            output_pixel_width=output_pixel_width,\n",
    "            source_image_width=source_physical_width,\n",
    "            sphere_image=sphere_texture,\n",
    "            source_image=source_texture,\n",
    "            M_scale=mass_of_black_hole,\n",
    "            t_anim=t_animation,\n",
    "            prograde_disk=is_prograde,\n",
    "            blueprint_filename=blueprint_filename,\n",
    "            window_width=window_width\n",
    "        )\n",
    "\n",
    "    print(\"\\n--- All frames generated successfully. ---\")\n",
    "\n",
    "    # Optional: Display the first frame in the notebook for verification\n",
    "    first_frame_path = os.path.join(output_folder, \"frame_0000.png\")\n",
    "    if os.path.exists(first_frame_path):\n",
    "        print(\"Displaying first generated frame:\")\n",
    "        display(IPImage(filename=first_frame_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2801c51d",
   "metadata": {},
   "source": [
    "<a id='video_encoder'></a>\n",
    "## 1.k: Video Encoding Function\n",
    "\n",
    "Once all the individual animation frames have been rendered as PNG images, the final step is to combine them into a standard video file (e.g., an MP4). This task is handled by the `encode_video_from_frames` function.\n",
    "\n",
    "This function is a wrapper around the powerful, industry-standard command-line tool **FFmpeg**. It programmatically constructs and executes an FFmpeg command that:\n",
    "1.  Reads the sequence of PNG images from the specified folder.\n",
    "2.  Encodes them using the efficient `libx264` video codec.\n",
    "3.  Sets the frame rate and quality of the output video.\n",
    "4.  Saves the final result to the specified output video path.\n",
    "\n",
    "**Note:** This function requires that FFmpeg is installed on the system and is accessible from the command line.\n",
    "\n",
    "### Function: `encode_video_from_frames()`\n",
    "*   **Inputs:**\n",
    "    *   `image_folder`: The directory containing the input PNG frames.\n",
    "    *   `output_video_path`: The full path for the output MP4 video file.\n",
    "    *   `frame_rate`: The desired frames per second for the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad79e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def encode_video_from_frames(\n",
    "    image_folder: str,\n",
    "    output_video_path: str,\n",
    "    frame_rate: int = 30,\n",
    "    crf: int = 18\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Encodes a sequence of image frames into a video file using FFmpeg.\n",
    "\n",
    "    This function requires FFmpeg to be installed and accessible in the system's PATH.\n",
    "\n",
    "    Args:\n",
    "        image_folder: The directory containing the sequentially named image frames.\n",
    "        output_video_path: The full path for the output video file (e.g., 'output/animation.mp4').\n",
    "        frame_rate: The frame rate for the output video.\n",
    "        crf: The Constant Rate Factor for the x264 codec (lower is higher quality).\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting Video Encoding ---\")\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    output_dir = os.path.dirname(output_video_path)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Construct the FFmpeg command as a list of arguments\n",
    "    command = [\n",
    "        'ffmpeg',\n",
    "        '-y',  # Overwrite output file if it exists\n",
    "        '-framerate', str(frame_rate),\n",
    "        '-i', os.path.join(image_folder, 'frame_%04d.png'),\n",
    "        '-c:v', 'libx264',\n",
    "        '-pix_fmt', 'yuv420p',\n",
    "        '-r', str(frame_rate),\n",
    "        '-crf', str(crf),\n",
    "        output_video_path\n",
    "    ]\n",
    "\n",
    "    print(f\"Running FFmpeg command:\\n{' '.join(command)}\")\n",
    "\n",
    "    try:\n",
    "        # Run the command\n",
    "        # capture_output=True will store stdout and stderr in the result object\n",
    "        # text=True will decode them as text\n",
    "        result = subprocess.run(\n",
    "            command,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True  # This will raise a CalledProcessError if FFmpeg returns a non-zero exit code\n",
    "        )\n",
    "        print(\"\\n--- FFmpeg stdout ---\")\n",
    "        print(result.stdout)\n",
    "        print(\"\\n--- FFmpeg stderr ---\")\n",
    "        print(result.stderr)\n",
    "        print(f\"\\n[✓] Video encoding successful. File saved to '{output_video_path}'\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\n[!] ERROR: FFmpeg not found.\")\n",
    "        print(\"Please ensure FFmpeg is installed and accessible in your system's PATH.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n[!] ERROR: FFmpeg failed with exit code {e.returncode}.\")\n",
    "        print(\"\\n--- FFmpeg stdout ---\")\n",
    "        print(e.stdout)\n",
    "        print(\"\\n--- FFmpeg stderr ---\")\n",
    "        print(e.stderr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8632d17",
   "metadata": {},
   "source": [
    "<a id='runner'></a>\n",
    "## 1.l: C Code Runner and Blueprint Manager\n",
    "\n",
    "During the process of generating animations or comparing different simulation runs, it is often necessary to run the C integrator multiple times with different parameters and save each output blueprint file under a unique name.\n",
    "\n",
    "The `run_integrator_and_rename_blueprint` function is a Python helper that automates this process. It:\n",
    "1.  Takes the path to the C project and the desired command-line arguments as input.\n",
    "2.  Executes the compiled C program using Python's `subprocess` module.\n",
    "3.  Captures the output and checks for any errors.\n",
    "4.  If the run is successful, it finds the newly created `blueprint.bin` file and renames it to a user-specified output name, moving it to a designated folder.\n",
    "\n",
    "This utility is particularly useful for creating a library of pre-computed blueprint files for different physical scenarios (e.g., different black hole spins or camera positions), which can then be used to render images without needing to re-run the expensive geodesic integration.\n",
    "\n",
    "### Function: `run_integrator_and_rename_blueprint()`\n",
    "*   **Inputs:**\n",
    "    *   `project_dir`: The path to the C project directory.\n",
    "    *   `executable_name`: The name of the compiled C program.\n",
    "    *   `args_string`: A string containing the command-line arguments to pass to the C program.\n",
    "    *   `output_blueprint_name`: The new name for the output blueprint file.\n",
    "    *   `bin_folder`: The subfolder where the renamed blueprint will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797597e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def run_integrator_and_rename_blueprint(\n",
    "    project_dir: str,\n",
    "    executable_name: str,\n",
    "    args_string: str,\n",
    "    output_blueprint_name: str,\n",
    "    # NEW: Added parameter for the output directory for blueprints\n",
    "    bin_folder: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Runs the C geodesic integrator and moves the resulting blueprint file\n",
    "    to a specified subfolder.\n",
    "    \"\"\"\n",
    "    command_to_run = f\"./{executable_name} {args_string}\"\n",
    "    \n",
    "    print(f\"--- Running command in directory '{project_dir}': {command_to_run} ---\")\n",
    "\n",
    "    try:\n",
    "        process_result = subprocess.run(\n",
    "            command_to_run,\n",
    "            shell=True,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True,\n",
    "            cwd=project_dir\n",
    "        )\n",
    "        print(process_result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"ERROR: The C program exited with an error (exit code {e.returncode}).\")\n",
    "        print(\"--- Standard Error ---\")\n",
    "        print(e.stderr)\n",
    "        return\n",
    "\n",
    "    # The C code always outputs 'blueprint.bin' to its own directory.\n",
    "    original_blueprint_path = os.path.join(project_dir, \"blueprint.bin\")\n",
    "    \n",
    "    # --- MODIFICATION: Move blueprint to the specified subfolder ---\n",
    "    # First, ensure the destination folder exists.\n",
    "    destination_folder = os.path.join(project_dir, bin_folder)\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    \n",
    "    # Construct the final path for the renamed blueprint.\n",
    "    new_blueprint_path = os.path.join(destination_folder, output_blueprint_name)\n",
    "\n",
    "    if os.path.exists(original_blueprint_path):\n",
    "        print(f\"Moving '{original_blueprint_path}' to '{new_blueprint_path}'...\")\n",
    "        shutil.move(original_blueprint_path, new_blueprint_path)\n",
    "        print(\"--- Run complete. ---\")\n",
    "    else:\n",
    "        print(\"Warning: 'blueprint.bin' was not created by the C program.\")\n",
    "\n",
    "print(\"Helper function `run_integrator_and_rename_blueprint` defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b385b9",
   "metadata": {},
   "source": [
    "<a id='spinning_disk_animator'></a>\n",
    "## 1.m: Spinning Disk Animation Orchestrator\n",
    "\n",
    "This function, `generate_spinning_disk_animation_frames`, is a specialized orchestrator designed for a common and powerful animation technique. Instead of re-running the expensive C geodesic integrator for every single frame, this method runs it **only once** to generate a single, master `light_blueprint.bin` file. It then uses this static blueprint to render a full animation of a spinning accretion disk.\n",
    "\n",
    "This is possible because the blueprint contains the light-travel time (`t_s`) for every ray that hits the source plane. The renderer can use this information to calculate where each piece of the disk *would have been* at the moment it emitted the light that is now arriving at the camera.\n",
    "\n",
    "The function orchestrates the following workflow:\n",
    "1.  **Create Temporary Parameter File**: For each frame, it creates a temporary `.par` file. The key action is that it sets the `t_start` parameter to a different value for each frame, effectively stepping the \"camera time\" forward through the animation.\n",
    "2.  **Run C Integrator**: It calls the compiled C executable, passing it the temporary parameter file. This generates a new `light_blueprint.bin` for each frame's unique `t_start`.\n",
    "3.  **Render Frame**: It calls the `generate_static_lensed_image` renderer, passing it the newly generated blueprint for that frame. This creates one PNG image.\n",
    "4.  **Cleanup (Optional)**: To save disk space, it can automatically delete the large temporary blueprint file after the corresponding PNG frame has been rendered.\n",
    "\n",
    "This approach is highly efficient for creating long animations of dynamic disks in stationary spacetimes, as the costly ray-tracing is performed once per frame, but the rendering itself is very fast.\n",
    "\n",
    "### Function: `generate_spinning_disk_animation_frames()`\n",
    "*   **Key Inputs:**\n",
    "    *   `num_frames`: The total number of frames to generate.\n",
    "    *   `total_animation_duration`: The total coordinate time the animation should span.\n",
    "    *   `project_dir`, `executable_name`, `base_par_filename`: Information needed to run the C code.\n",
    "    *   `blueprint_folder`, `frames_folder`: Output directories for temporary data and final images.\n",
    "    *   `save_blueprints`: A boolean flag to control whether the per-frame blueprint files are kept or deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883eaf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from IPython.display import display, Image as IPImage\n",
    "from typing import Union\n",
    "\n",
    "def generate_spinning_disk_animation_frames(\n",
    "    # --- Required Positional Arguments ---\n",
    "    num_frames: int,\n",
    "    total_animation_duration: float,\n",
    "    project_dir: str,\n",
    "    executable_name: str,\n",
    "    base_par_filename: str,\n",
    "    blueprint_folder: str,\n",
    "    frames_folder: str,\n",
    "    output_pixel_width: int,\n",
    "    source_image_width: float,\n",
    "    sphere_image: Union[str, np.ndarray],\n",
    "    source_image: Union[str, np.ndarray],\n",
    "    window_width: float,\n",
    "    \n",
    "    # --- Optional Keyword Arguments ---\n",
    "    start_time_offset: float = 0.0,\n",
    "    save_blueprints: bool = False,\n",
    "    **kwargs # For gamma, intensity_scale, etc.\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generates a sequence of frames for a spinning disk animation.\n",
    "    \n",
    "    This version includes a `save_blueprints` flag. If False (default), it\n",
    "    deletes the large temporary blueprint file for each frame after rendering,\n",
    "    saving significant disk space.\n",
    "    \"\"\"\n",
    "    print(f\"--- Generating {num_frames} Frames for Spinning Disk Animation ---\")\n",
    "    if not save_blueprints:\n",
    "        print(\"    (Temporary blueprints will be deleted after each frame is rendered)\")\n",
    "    \n",
    "    full_blueprint_dir = os.path.join(project_dir, blueprint_folder)\n",
    "    full_frames_dir = os.path.join(project_dir, frames_folder)\n",
    "    os.makedirs(full_blueprint_dir, exist_ok=True)\n",
    "    os.makedirs(full_frames_dir, exist_ok=True)\n",
    "\n",
    "    base_par_lines = []\n",
    "    with open(os.path.join(project_dir, base_par_filename), 'r') as f:\n",
    "        for line in f:\n",
    "            if not line.strip().startswith(\"t_start\"):\n",
    "                base_par_lines.append(line)\n",
    "    base_par_content = \"\".join(base_par_lines)\n",
    "\n",
    "    # --- Main Animation Loop ---\n",
    "    for i in range(num_frames):\n",
    "        time_progress = (i / (num_frames - 1)) * total_animation_duration if num_frames > 1 else 0\n",
    "        current_t_start = start_time_offset + time_progress\n",
    "        \n",
    "        print(f\"\\n--- Processing Frame {i+1}/{num_frames}: t_start = {current_t_start:.2f} M ---\")\n",
    "        \n",
    "        # 1. Create temporary parameter file\n",
    "        temp_par_content = base_par_content + f\"\\nt_start = {current_t_start:.4f}\\n\"\n",
    "        temp_par_filename = \"temp_anim_frame.par\"\n",
    "        full_temp_par_path = os.path.join(project_dir, temp_par_filename)\n",
    "        with open(full_temp_par_path, \"w\") as f:\n",
    "            f.write(temp_par_content)\n",
    "\n",
    "        # 2. Run the C integrator\n",
    "        command_to_run = f\"./{executable_name} {temp_par_filename}\"\n",
    "        try:\n",
    "            subprocess.run(\n",
    "                command_to_run, shell=True, capture_output=True, text=True, check=True, cwd=project_dir\n",
    "            )\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"ERROR: The C program exited with an error for frame {i}.\")\n",
    "            print(\"--- Standard Error ---\")\n",
    "            print(e.stderr)\n",
    "            continue\n",
    "\n",
    "        # 3. Move the output blueprint to its temporary location\n",
    "        original_blueprint_path = os.path.join(project_dir, \"light_blueprint.bin\")\n",
    "        blueprint_frame_name = f\"blueprint_frame_{i:04d}.bin\"\n",
    "        temp_blueprint_path = os.path.join(full_blueprint_dir, blueprint_frame_name)\n",
    "        \n",
    "        if os.path.exists(original_blueprint_path):\n",
    "            shutil.move(original_blueprint_path, temp_blueprint_path)\n",
    "        else:\n",
    "            print(f\"ERROR: C code ran but did not produce 'light_blueprint.bin'. Skipping rendering.\")\n",
    "            continue\n",
    "            \n",
    "        # 4. Render the image for this frame\n",
    "        image_frame_name = os.path.join(full_frames_dir, f\"frame_{i:04d}.png\")\n",
    "        \n",
    "        generate_static_lensed_image(\n",
    "            output_filename=image_frame_name,\n",
    "            output_pixel_width=output_pixel_width,\n",
    "            source_image_width=source_image_width,\n",
    "            sphere_image=sphere_image,\n",
    "            source_image=source_image,\n",
    "            blueprint_filename=temp_blueprint_path,\n",
    "            window_width=window_width,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # --- 5. NEW: Clean up the temporary blueprint file ---\n",
    "        if not save_blueprints:\n",
    "            if os.path.exists(temp_blueprint_path):\n",
    "                os.remove(temp_blueprint_path)\n",
    "                print(f\"  -> Deleted temporary blueprint: {blueprint_frame_name}\")\n",
    "\n",
    "    # --- Final Cleanup ---\n",
    "    # If we weren't saving blueprints, the blueprint folder should be empty.\n",
    "    # We can remove it to keep the project directory clean.\n",
    "    if not save_blueprints:\n",
    "        try:\n",
    "            # Check if the directory is empty before removing\n",
    "            if not os.listdir(full_blueprint_dir):\n",
    "                os.rmdir(full_blueprint_dir)\n",
    "        except OSError as e:\n",
    "            print(f\"Could not remove empty blueprint directory: {e}\")\n",
    "\n",
    "    print(f\"\\n--- All {num_frames} frames generated successfully in '{full_frames_dir}'. ---\")\n",
    "    \n",
    "    first_frame_path = os.path.join(full_frames_dir, \"frame_0000.png\")\n",
    "    if os.path.exists(first_frame_path):\n",
    "        print(\"Displaying first generated frame:\")\n",
    "        display(IPImage(filename=first_frame_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c46a2e",
   "metadata": {},
   "source": [
    "<a id='blueprint_comparator'></a>\n",
    "## 1.n: Blueprint Comparison Utility for Validation\n",
    "\n",
    "This cell defines the `compare_blueprint_files` function, a powerful diagnostic tool for validating the determinism and correctness of the C integrator.\n",
    "\n",
    "For a stationary spacetime like Kerr or Schwarzschild, the path a photon takes should depend only on its initial position and momentum, not on the initial coordinate time `t_start`. Therefore, running the exact same simulation with two different `t_start` values should produce numerically identical blueprint files.\n",
    "\n",
    "This function tests that hypothesis. It performs a two-level comparison:\n",
    "1.  **Byte-for-Byte Check**: It first performs a fast, exact comparison of the two binary files. If they are identical, it confirms the C code is producing deterministic, bit-for-bit reproducible results.\n",
    "2.  **Detailed Numerical Check**: If the byte-for-byte check fails (which can sometimes happen due to harmless floating-point representation noise), the function then loads both files into `numpy` structured arrays. It compares each field, checking integer fields for exact equality and floating-point fields for equality within a small numerical tolerance.\n",
    "\n",
    "If the numerical check also fails, it provides a detailed report of which fields differed and for which rays. This is an essential tool for debugging, as it can quickly determine if a change in the C code has introduced non-deterministic behavior or broken the physics.\n",
    "\n",
    "### Function: `compare_blueprint_files()`\n",
    "*   **Inputs:**\n",
    "    *   `file1_path`, `file2_path`: The paths to the two blueprint files to be compared.\n",
    "    *   `detailed_report`: If `True`, prints a sample of the differing records.\n",
    "    *   `tolerance`: The numerical tolerance used for comparing floating-point values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8840586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def compare_blueprint_files(\n",
    "    file1_path: str,\n",
    "    file2_path: str,\n",
    "    detailed_report: bool = False,\n",
    "    tolerance: float = 1e-9\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Compares two light_blueprint.bin files to check for differences.\n",
    "\n",
    "    This function performs a byte-for-byte comparison and, if they differ,\n",
    "    a detailed field-by-field numerical comparison to identify exactly\n",
    "    what has changed.\n",
    "\n",
    "    Args:\n",
    "        file1_path: Path to the first blueprint file.\n",
    "        file2_path: Path to the second blueprint file.\n",
    "        detailed_report: If True, prints the first few differing records.\n",
    "        tolerance: The absolute tolerance for floating-point comparisons.\n",
    "\n",
    "    Returns:\n",
    "        True if the files are considered identical, False otherwise.\n",
    "    \"\"\"\n",
    "    print(f\"--- Comparing Blueprint Files ---\")\n",
    "    print(f\"File 1: {file1_path}\")\n",
    "    print(f\"File 2: {file2_path}\")\n",
    "\n",
    "    # --- 1. Basic File Checks ---\n",
    "    if not os.path.exists(file1_path):\n",
    "        print(f\"ERROR: File not found: {file1_path}\")\n",
    "        return False\n",
    "    if not os.path.exists(file2_path):\n",
    "        print(f\"ERROR: File not found: {file2_path}\")\n",
    "        return False\n",
    "\n",
    "    size1 = os.path.getsize(file1_path)\n",
    "    size2 = os.path.getsize(file2_path)\n",
    "\n",
    "    if size1 != size2:\n",
    "        print(f\"\\n[!] VERDICT: FILES ARE DIFFERENT (Sizes mismatch: {size1} vs {size2} bytes)\")\n",
    "        return False\n",
    "\n",
    "    # --- 2. Fast Byte-for-Byte Comparison ---\n",
    "    with open(file1_path, 'rb') as f1, open(file2_path, 'rb') as f2:\n",
    "        if f1.read() == f2.read():\n",
    "            print(\"\\n[✓] VERDICT: FILES ARE IDENTICAL (Byte-for-byte comparison passed).\")\n",
    "            print(\"This confirms the C code is producing deterministic output.\")\n",
    "            return True\n",
    "\n",
    "    print(\"\\n[!] NOTICE: Files have the same size but their byte content differs. Performing detailed analysis...\")\n",
    "\n",
    "    # --- 3. Detailed Numerical Comparison (if byte comparison fails) ---\n",
    "    # This dtype must match the one used for rendering.\n",
    "    BLUEPRINT_DTYPE = np.dtype([\n",
    "        ('termination_type', np.int32),\n",
    "        ('y_w', 'f8'), ('z_w', 'f8'),\n",
    "        ('stokes_I', 'f8'), ('lambda_observed', 'f8'),\n",
    "        ('y_s', 'f8'), ('z_s', 'f8'),\n",
    "        ('final_theta', 'f8'), ('final_phi', 'f8'),\n",
    "        ('L_w', 'f8'), ('t_w', 'f8'),\n",
    "        ('L_s', 'f8'), ('t_s', 'f8'),\n",
    "    ], align=False)\n",
    "\n",
    "    data1 = np.fromfile(file1_path, dtype=BLUEPRINT_DTYPE)\n",
    "    data2 = np.fromfile(file2_path, dtype=BLUEPRINT_DTYPE)\n",
    "\n",
    "    if len(data1) != len(data2):\n",
    "        print(f\"ERROR: Record count mismatch after loading: {len(data1)} vs {len(data2)}\")\n",
    "        return False\n",
    "\n",
    "    # Compare integer fields exactly\n",
    "    term_type_mismatch = np.any(data1['termination_type'] != data2['termination_type'])\n",
    "\n",
    "    # Compare float fields with a tolerance\n",
    "    float_fields = ['y_w', 'z_w', 'stokes_I', 'lambda_observed', 'y_s', 'z_s',\n",
    "                    'final_theta', 'final_phi', 'L_w', 't_w', 'L_s', 't_s']\n",
    "    \n",
    "    mismatches = {}\n",
    "    are_floats_different = False\n",
    "    for field in float_fields:\n",
    "        diff = np.abs(data1[field] - data2[field])\n",
    "        if np.any(diff > tolerance):\n",
    "            mismatches[field] = np.where(diff > tolerance)[0]\n",
    "            are_floats_different = True\n",
    "\n",
    "    if not term_type_mismatch and not are_floats_different:\n",
    "        print(\"\\n[✓] VERDICT: FILES ARE NUMERICALLY IDENTICAL (within tolerance).\")\n",
    "        print(\"The small byte differences are likely due to floating-point representation noise, which is acceptable.\")\n",
    "        return True\n",
    "    \n",
    "    print(\"\\n[!] VERDICT: FILES ARE NUMERICALLY DIFFERENT.\")\n",
    "    print(\"This indicates the C code output is NOT deterministic and depends on t_start.\")\n",
    "\n",
    "    if term_type_mismatch:\n",
    "        mismatch_indices = np.where(data1['termination_type'] != data2['termination_type'])[0]\n",
    "        print(f\"\\nFound {len(mismatch_indices)} records with mismatched termination types.\")\n",
    "        if detailed_report:\n",
    "            print(\"--- First 5 Mismatched Termination Records ---\")\n",
    "            for i in mismatch_indices[:5]:\n",
    "                print(f\"  Record {i}: Type 1 = {data1['termination_type'][i]}, Type 2 = {data2['termination_type'][i]}\")\n",
    "\n",
    "    if are_floats_different:\n",
    "        print(\"\\nFound differences in the following floating-point fields:\")\n",
    "        for field, indices in mismatches.items():\n",
    "            print(f\"  - Field '{field}': {len(indices)} mismatched records.\")\n",
    "            if detailed_report:\n",
    "                print(\"    --- First 5 Mismatched Float Records ---\")\n",
    "                for i in indices[:5]:\n",
    "                    print(f\"      Record {i}: Val 1 = {data1[field][i]:.6e}, Val 2 = {data2[field][i]:.6e}, Diff = {np.abs(data1[field][i] - data2[field][i]):.2e}\")\n",
    "\n",
    "    return False\n",
    "\n",
    "# --- How to Use This Cell ---\n",
    "# 1. Run your C code with t_start=0 and the camera pointed away from the disk.\n",
    "# 2. Rename the output: mv project/photon_geodesic_integrator/light_blueprint.bin project/photon_geodesic_integrator/blueprint_t0.bin\n",
    "# 3. Run your C code again with t_start=1000 (or any other value).\n",
    "# 4. Rename the output: mv project/photon_geodesic_integrator/light_blueprint.bin project/photon_geodesic_integrator/blueprint_t1000.bin\n",
    "# 5. Run this cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324ad4e",
   "metadata": {},
   "source": [
    "# Plotting for error in conserved values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdfbc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def plot_conservation_error_distribution(\n",
    "    project_dir: str = \"project/photon_geodesic_integrator\",\n",
    "    input_filename: str = \"conservation_errors.txt\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads the conservation error log file and plots scatter plots of the\n",
    "    relative errors for E, L, and Q, colored by termination reason.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Conservation Error Distribution Plots ---\")\n",
    "\n",
    "    # --- 1. Construct the full path and load the data using pandas ---\n",
    "    full_path = os.path.join(project_dir, input_filename)\n",
    "\n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"ERROR: Error log file not found at '{full_path}'\")\n",
    "        print(\"Please ensure you have compiled and run the C code with the logging feature enabled.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Define the column names to match the header in the C code's output\n",
    "        column_names = ['photon_idx', 'dE_relative', 'dL_relative', 'dQ_relative', \n",
    "                        'Q_initial', 'Q_final', 'termination_type']\n",
    "        \n",
    "        # Use the updated 'sep' argument to avoid the FutureWarning\n",
    "        df = pd.read_csv(full_path, sep=r'\\s+', comment='#', names=column_names)\n",
    "        \n",
    "        print(f\"Successfully loaded error data for {len(df)} photons.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load or parse the data file '{full_path}'.\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Prepare Data and Define Labels ---\n",
    "    # Replace zeros with a small number for log scale plotting\n",
    "    df['dE_relative'] = df['dE_relative'].replace(0, 1e-16)\n",
    "    df['dL_relative'] = df['dL_relative'].replace(0, 1e-16)\n",
    "    df['dQ_relative'] = df['dQ_relative'].replace(0, 1e-16)\n",
    "    \n",
    "    # Define termination labels for the legend (matching the C enum values)\n",
    "    termination_map = {\n",
    "        0: 'BH Capture (p^t exceeded)',\n",
    "        1: 'Disk Intersection',\n",
    "        2: 'Source Plane',\n",
    "        3: 'Celestial Sphere',\n",
    "        4: 'ACTIVE (Error)',\n",
    "        5: 'RKF45 Failure',\n",
    "        6: 'Generic Failure',\n",
    "        7: 'Time Exceeded',\n",
    "        8: 'Slot Manager Error'\n",
    "    }\n",
    "    df['termination_label'] = df['termination_type'].map(termination_map).fillna('Unknown')\n",
    "\n",
    "    # --- 3. Create the Plots (One for Each Conserved Quantity) ---\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    # Create a figure with 3 subplots (3 rows, 1 column)\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 21), sharex=True)\n",
    "    fig.suptitle('Distribution of Relative Conservation Errors by Termination Type', fontsize=20)\n",
    "\n",
    "    # List of quantities to plot\n",
    "    quantities = {\n",
    "        'E': 'dE_relative',\n",
    "        'L': 'dL_relative',\n",
    "        'Q': 'dQ_relative'\n",
    "    }\n",
    "    \n",
    "    # Use a consistent color palette for termination types across all plots\n",
    "    unique_labels = df['termination_label'].unique()\n",
    "    colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "    color_map = {label: colors(i) for i, label in enumerate(unique_labels)}\n",
    "\n",
    "    # --- Loop to create each subplot ---\n",
    "    for i, (name, col) in enumerate(quantities.items()):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Group data by termination type to plot with different colors\n",
    "        for label, group_df in df.groupby('termination_label'):\n",
    "            # We plot the error vs the photon index to spread the data out\n",
    "            ax.scatter(\n",
    "                group_df['photon_idx'], \n",
    "                group_df[col], \n",
    "                label=label,\n",
    "                s=5, # Small marker size for many points\n",
    "                alpha=0.7,\n",
    "                color=color_map[label]\n",
    "            )\n",
    "        \n",
    "        ax.set_title(f'Relative Error in Conserved Quantity: {name}', fontsize=14)\n",
    "        ax.set_ylabel('Relative Error', fontsize=12)\n",
    "        ax.set_yscale('log')\n",
    "        ax.grid(True, which=\"both\", ls=\"--\")\n",
    "        \n",
    "        # Add a horizontal line to show a typical \"good\" conservation threshold\n",
    "        ax.axhline(1e-7, color='red', linestyle='--', alpha=0.7, label='High Precision Threshold (1e-7)')\n",
    "        \n",
    "        # Place the legend outside the plot\n",
    "        if i == 0: # Only add legend to the top plot\n",
    "             ax.legend(title=\"Termination Reason\", loc='upper left', bbox_to_anchor=(1.02, 1.0))\n",
    "\n",
    "    # Set the shared x-axis label on the bottom plot\n",
    "    axes[-1].set_xlabel('Photon Index', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 0.96]) # Adjust layout to make space for legend\n",
    "    plt.show()\n",
    "\n",
    "# --- How to Run ---\n",
    "# plot_conservation_error_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0202cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def plot_failed_photon_window_positions(\n",
    "    project_dir: str = \"project/photon_geodesic_integrator\",\n",
    "    input_filename: str = \"conservation_errors.txt\",\n",
    "    scan_density: int = 512,\n",
    "    window_size: float = 1.5,\n",
    "    error_threshold: float = 1e-7\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads the conservation error log, identifies photons that fail the precision\n",
    "    threshold, calculates their initial window positions, and plots them in a 2D\n",
    "    scatter plot, color-coded by the number of failed conservation laws.\n",
    "    \n",
    "    UPDATED to read the new file format that includes the final_t column.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Window Plot of High-Error Photons ---\")\n",
    "\n",
    "    # --- 1. Load the conservation error data ---\n",
    "    full_path = os.path.join(project_dir, input_filename)\n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"ERROR: Error log file not found at '{full_path}'\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # UPDATED: Added 'final_t' to the column names to match the new file format\n",
    "        column_names = ['photon_idx', 'dE_relative', 'dL_relative', 'dQ_relative', \n",
    "                        'Q_initial', 'Q_final', 'termination_type', 'final_t']\n",
    "        \n",
    "        df = pd.read_csv(full_path, sep=r'\\s+', comment='#', names=column_names)\n",
    "        print(f\"Successfully loaded error data for {len(df)} photons.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load or parse data file. Exception: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Identify failed photons and count failures ---\n",
    "    failed_E = df['dE_relative'] > error_threshold\n",
    "    failed_L = df['dL_relative'] > error_threshold\n",
    "    failed_Q = df['dQ_relative'] > error_threshold\n",
    "\n",
    "    df['failure_count'] = failed_E.astype(int) + failed_L.astype(int) + failed_Q.astype(int)\n",
    "\n",
    "    failed_photons_df = df[df['failure_count'] > 0].copy()\n",
    "    \n",
    "    if len(failed_photons_df) == 0:\n",
    "        print(\"Congratulations! No photons failed the high-precision threshold.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Found {len(failed_photons_df)} photons that failed the precision threshold of {error_threshold:.1e}.\")\n",
    "\n",
    "    # --- 3. Calculate window positions for the failed photons ---\n",
    "    photon_indices = failed_photons_df['photon_idx'].values\n",
    "    j_indices = photon_indices // scan_density\n",
    "    k_indices = photon_indices % scan_density\n",
    "    \n",
    "    pixel_width = window_size / scan_density\n",
    "    x_pix = -window_size / 2.0 + (k_indices + 0.5) * pixel_width\n",
    "    y_pix = -window_size / 2.0 + (j_indices + 0.5) * pixel_width\n",
    "    \n",
    "    failed_photons_df['x_pix'] = x_pix\n",
    "    failed_photons_df['y_pix'] = y_pix\n",
    "\n",
    "    # --- 4. Create the 2D Scatter Plot ---\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    color_map = {1: 'gold', 2: 'orange', 3: 'red'}\n",
    "    label_map = {\n",
    "        1: f'Failed 1 Quantity',\n",
    "        2: f'Failed 2 Quantities',\n",
    "        3: f'Failed 3 Quantities'\n",
    "    }\n",
    "\n",
    "    for count, group_df in failed_photons_df.groupby('failure_count'):\n",
    "        ax.scatter(\n",
    "            group_df['x_pix'], \n",
    "            group_df['y_pix'],\n",
    "            color=color_map.get(count, 'grey'),\n",
    "            label=f\"{label_map.get(count, 'Unknown')} ({len(group_df)} photons)\",\n",
    "            s=10,\n",
    "            alpha=0.8\n",
    "        )\n",
    "\n",
    "    # --- 5. Customize the Plot ---\n",
    "    ax.set_title('Window Positions of Photons Failing Conservation Checks', fontsize=16)\n",
    "    ax.set_xlabel('Window X Coordinate (x_pix) [M]', fontsize=12)\n",
    "    ax.set_ylabel('Window Y Coordinate (y_pix) [M]', fontsize=12)\n",
    "    \n",
    "    ax.set_xlim(-window_size / 2.0, window_size / 2.0)\n",
    "    ax.set_ylim(-window_size / 2.0, window_size / 2.0)\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    \n",
    "    center_circle = plt.Circle((0, 0), 0.1, color='black', alpha=0.5, label='Central Region')\n",
    "    ax.add_artist(center_circle)\n",
    "    \n",
    "    ax.legend(title=\"Failure Severity\")\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d19d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def plot_conservation_error_distribution(\n",
    "    project_dir: str = \"project/photon_geodesic_integrator\",\n",
    "    input_filename: str = \"conservation_errors.txt\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads the conservation error log file and generates two plots:\n",
    "    1. A scatter plot of errors vs. photon index, colored by termination type.\n",
    "    2. A scatter plot of error vs. final integration time.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Conservation Error Distribution Plots ---\")\n",
    "\n",
    "    # --- 1. Load the data using pandas ---\n",
    "    full_path = os.path.join(project_dir, input_filename)\n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"ERROR: Error log file not found at '{full_path}'\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # UPDATED: Added 'final_t' to the column names\n",
    "        column_names = ['photon_idx', 'dE_relative', 'dL_relative', 'dQ_relative', \n",
    "                        'Q_initial', 'Q_final', 'termination_type', 'final_t']\n",
    "        \n",
    "        df = pd.read_csv(full_path, sep=r'\\s+', comment='#', names=column_names)\n",
    "        print(f\"Successfully loaded error data for {len(df)} photons.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load or parse the data file '{full_path}'. Exception: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Prepare Data and Define Labels ---\n",
    "    df['dL_relative'] = df['dL_relative'].replace(0, 1e-16)\n",
    "    \n",
    "    termination_map = {\n",
    "        0: 'BH Capture (p^t exceeded)', 1: 'Disk Intersection', 2: 'Source Plane',\n",
    "        3: 'Celestial Sphere', 4: 'ACTIVE (Error)', 5: 'RKF45 Failure',\n",
    "        6: 'Generic Failure', 7: 'Time Exceeded', 8: 'Slot Manager Error'\n",
    "    }\n",
    "    df['termination_label'] = df['termination_type'].map(termination_map).fillna('Unknown')\n",
    "\n",
    "    # --- 3. Create the Plots ---\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    # Create a figure with 2 subplots (1 row, 2 columns)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    fig.suptitle('Analysis of Conservation Errors', fontsize=20)\n",
    "\n",
    "    # Use a consistent color palette for termination types\n",
    "    unique_labels = df['termination_label'].unique()\n",
    "    colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "    color_map = {label: colors(i) for i, label in enumerate(unique_labels)}\n",
    "\n",
    "    # --- PLOT 1: Error vs. Photon Index (as before) ---\n",
    "    ax1 = axes[0]\n",
    "    for label, group_df in df.groupby('termination_label'):\n",
    "        ax1.scatter(group_df['photon_idx'], group_df['dL_relative'], \n",
    "                    label=label, s=5, alpha=0.7, color=color_map[label])\n",
    "    \n",
    "    ax1.set_title('Angular Momentum Error vs. Photon Index', fontsize=14)\n",
    "    ax1.set_xlabel('Photon Index', fontsize=12)\n",
    "    ax1.set_ylabel('Relative Error in L', fontsize=12)\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.grid(True, which=\"both\", ls=\"--\")\n",
    "    ax1.legend(title=\"Termination Reason\")\n",
    "\n",
    "    # --- PLOT 2: NEW - Error vs. Final Time ---\n",
    "    ax2 = axes[1]\n",
    "    for label, group_df in df.groupby('termination_label'):\n",
    "        ax2.scatter(group_df['final_t'], group_df['dL_relative'], \n",
    "                    label=label, s=5, alpha=0.7, color=color_map[label])\n",
    "\n",
    "    ax2.set_title('Angular Momentum Error vs. Final Integration Time', fontsize=14)\n",
    "    ax2.set_xlabel('Final Coordinate Time (t)', fontsize=12)\n",
    "    ax2.set_ylabel('Relative Error in L', fontsize=12)\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.grid(True, which=\"both\", ls=\"--\")\n",
    "    # ax2.legend(title=\"Termination Reason\") # Legend can be omitted here if it's the same as plot 1\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# --- How to Run ---\n",
    "plot_conservation_error_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf3179e",
   "metadata": {},
   "source": [
    "# Compare blueprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c1ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to your two blueprint files\n",
    "blueprint_t0_path = \"project/photon_geodesic_integrator/light_blueprint.bin\"\n",
    "blueprint_t1000_path = \"project/photon_geodesic_integrator/light_blueprint_0.bin\"\n",
    "\n",
    "# Run the comparison with a detailed report\n",
    "are_identical = compare_blueprint_files(blueprint_t0_path, blueprint_t1000_path, detailed_report=True)\n",
    "\n",
    "if are_identical:\n",
    "    print(\"\\nCONCLUSION: The C code is exonerated. The issue is not in the geodesic integration.\")\n",
    "else:\n",
    "    print(\"\\nCONCLUSION: The C code is implicated. The integration results depend on t_start, which should not happen for a stationary metric.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c497c",
   "metadata": {},
   "source": [
    "# Blueprints stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52220a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Call the function with your blueprint file and desired bin width ---\n",
    "blueprint_filename=\"project/photon_geodesic_integrator/light_blueprint.bin\"\n",
    "\n",
    "analyze_blueprint()\n",
    "\n",
    "view_binary_blueprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab59a53",
   "metadata": {},
   "source": [
    "# Setting all visualization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- Initializing Master Configuration for Visualization & Animation ---\")\n",
    "\n",
    "# --- Core File & Path Settings ---\n",
    "\n",
    "# Get the user's home directory (e.g., /home/daltonm)\n",
    "home_dir = os.path.expanduser('~')\n",
    "\n",
    "# Path to the directory where the C projects live\n",
    "# Assumes your notebook is in ~/Documents/\n",
    "base_project_dir = os.path.join(home_dir, \"Documents\", \"project\")\n",
    "\n",
    "# Path to the specific light integrator project\n",
    "p_light_integrator_dir = os.path.join(base_project_dir, \"photon_geodesic_integrator\")\n",
    "\n",
    "# --- NEW: Define the absolute output directory ---\n",
    "# This will create /home/daltonm/Documents/Generated_nrpy_images/\n",
    "p_output_basedir = os.path.join(home_dir, \"Documents\", \"Generated_nrpy_images\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Physics & Scene Parameters ---\n",
    "p_mass_of_black_hole = 1.0\n",
    "p_window_width = 1.5\n",
    "\n",
    "# --- Source & Background Texture Settings ---\n",
    "p_sphere_texture_file = \"starmap_2020.png\"\n",
    "\n",
    "# --- Procedural Disk Generation Parameters ---\n",
    "p_disk_inner_radius = 6.0\n",
    "p_disk_outer_radius = 25.0\n",
    "p_colormap = 'afmhot'\n",
    "p_disk_temp_power_law = -1.5\n",
    "p_ring_num = 4\n",
    "p_ring_contrast = 0.7\n",
    "p_ring_log_spacing = True\n",
    "p_doppler_factor = 0.3\n",
    "p_doppler_power = 3\n",
    "p_hotspot_num = 2\n",
    "p_hotspot_amplitude = 0.4\n",
    "p_hotspot_radius_center = 10.0\n",
    "p_hotspot_radius_width = 4.0\n",
    "p_shape_num_lobes = 0\n",
    "p_shape_inner_amplitude = 0.0\n",
    "p_shape_outer_amplitude = 0.0\n",
    "p_source_physical_width = 2 * (p_disk_outer_radius + p_shape_outer_amplitude)\n",
    "\n",
    "# --- General Image Quality & Rendering Settings ---\n",
    "p_static_image_pixel_width = 400\n",
    "p_animation_pixel_width = 400\n",
    "p_intensity_scale = 20.0\n",
    "p_gamma = 2.2\n",
    "p_lambda_min_nm = 500  # Fixed min wavelength for color consistency\n",
    "p_lambda_max_nm = 2250  # Fixed max wavelength\n",
    "\n",
    "\n",
    "# Path to the specific light integrator project\n",
    "p_light_integrator_dir = os.path.join(base_project_dir, \"photon_geodesic_integrator\")\n",
    "p_blueprint_filename = os.path.join(p_light_integrator_dir, \"light_blueprint.bin\")\n",
    "\n",
    "# --- Animation Settings ---\n",
    "p_anim_name = \"detailed_spiral\" # A descriptive name for this animation run\n",
    "# Subfolder for the individual frames\n",
    "p_anim_frames_folder = os.path.join(p_output_basedir, f\"{p_anim_name}_frames\")\n",
    "# Subfolder for the temporary blueprints (can be deleted after)\n",
    "p_anim_blueprint_folder = os.path.join(p_light_integrator_dir, f\"{p_anim_name}_blueprints\")\n",
    "# Final output filename for the video\n",
    "p_anim_video_file = os.path.join(p_output_basedir, f\"{p_anim_name}.mp4\")\n",
    "\n",
    "\n",
    "# --- CORRECTED PATH DEFINITIONS ---\n",
    "\n",
    "# The folder for temporary blueprints should be in the shared project directory\n",
    "blueprint_folder = os.path.join(base_project_dir, f\"{p_anim_name}_blueprints\")\n",
    "\n",
    "# The folder for the final PNG frames is already correctly defined in the master config\n",
    "frames_folder = p_anim_frames_folder \n",
    "# --- END CORRECTION ---\n",
    "\n",
    "\n",
    "p_anim_num_frames = 150\n",
    "p_anim_orbits_at_isco = 2.0\n",
    "p_anim_is_prograde = True\n",
    "p_anim_start_time = 70.0 # The starting coordinate time for the animation\n",
    "\n",
    "print(f\"Master configuration loaded.\")\n",
    "print(f\"All animation output will be saved in: {p_output_basedir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba0b21",
   "metadata": {},
   "source": [
    "# Disk Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_disk_texture = generate_advanced_disk_array(\n",
    "    pixel_width=1024, # High resolution for the source\n",
    "    disk_physical_width=p_source_physical_width,\n",
    "    colormap=p_colormap,\n",
    "    disk_inner_radius=p_disk_inner_radius,\n",
    "    disk_outer_radius=p_disk_outer_radius,\n",
    "    disk_temp_power_law=p_disk_temp_power_law,\n",
    "    ring_num=p_ring_num,\n",
    "    ring_contrast=p_ring_contrast,\n",
    "    ring_log_spacing=p_ring_log_spacing,\n",
    "    doppler_factor=p_doppler_factor,\n",
    "    doppler_power=p_doppler_power,\n",
    "    hotspot_num=p_hotspot_num,\n",
    "    shape_num_lobes=p_shape_num_lobes,\n",
    "    shape_inner_amplitude=p_shape_inner_amplitude,\n",
    "    shape_outer_amplitude=p_shape_outer_amplitude,\n",
    "    display_image=False # Show the disk we're about to render\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86facc9",
   "metadata": {},
   "source": [
    "# Standard Static Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7d2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image as IPImage\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- Generating a Standard Static Lensed Image from Radiative Transfer Data ---\")\n",
    "\n",
    "# --- 1. Define all inputs for the function call ---\n",
    "# All parameters are now read from the master configuration cell (prefix 'p_').\n",
    "\n",
    "# Define a unique name for the static image file\n",
    "static_image_name = \"batch_test_2.png\"\n",
    "p_static_image_pixel_width = 400\n",
    "output_filename = os.path.join(p_output_basedir, static_image_name)\n",
    "\n",
    "# Choose the source texture. This can be a filename or a pre-generated numpy array.\n",
    "# For this example, we use the advanced disk generated in a previous cell.\n",
    "try:\n",
    "    source_image_texture = source_disk_texture\n",
    "except NameError:\n",
    "    print(\"Warning: `advanced_disk_data` not found. Generating a default disk for this static image.\")\n",
    "    source_image_texture = generate_advanced_disk_array(display_image=False)\n",
    "\n",
    "# --- 2. The Function Call ---\n",
    "# This call now uses all the parameters defined in your master configuration cell.\n",
    "generate_static_lensed_image(\n",
    "    output_filename=output_filename,\n",
    "    output_pixel_width=p_static_image_pixel_width,\n",
    "    source_image_width=p_source_physical_width,\n",
    "    sphere_image=p_sphere_texture_file,\n",
    "    source_image=source_image_texture,\n",
    "    intensity_scale=p_intensity_scale,\n",
    "    lambda_min_nm=p_lambda_min_nm,\n",
    "    lambda_max_nm=p_lambda_max_nm,\n",
    "    gamma=p_gamma,\n",
    "    blueprint_filename=p_blueprint_filename,\n",
    "    window_width=p_window_width\n",
    ")\n",
    "\n",
    "# --- 3. Display the result ---\n",
    "if os.path.exists(output_filename):\n",
    "    print(f\"\\nDisplaying static image: '{output_filename}'\")\n",
    "    display(IPImage(filename=output_filename))\n",
    "else:\n",
    "    print(f\"\\nERROR: Image file was not created at '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a295dc",
   "metadata": {},
   "source": [
    "# Final Video Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af13cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FINAL ANIMATION EXECUTION CELL ---\n",
    "\n",
    "# 1. Generate the source disk texture to be used for rendering\n",
    "# This is done once before the main loop.\n",
    "print(\"--- Generating Source Disk Texture ---\")\n",
    "source_disk_texture = generate_advanced_disk_array(\n",
    "    pixel_width=1024, # High resolution for the source\n",
    "    disk_physical_width=p_source_physical_width,\n",
    "    colormap=p_colormap,\n",
    "    disk_inner_radius=p_disk_inner_radius,\n",
    "    disk_outer_radius=p_disk_outer_radius,\n",
    "    disk_temp_power_law=p_disk_temp_power_law,\n",
    "    ring_num=p_ring_num,\n",
    "    ring_contrast=p_ring_contrast,\n",
    "    ring_log_spacing=p_ring_log_spacing,\n",
    "    doppler_factor=p_doppler_factor,\n",
    "    doppler_power=p_doppler_power,\n",
    "    hotspot_num=p_hotspot_num,\n",
    "    shape_num_lobes=p_shape_num_lobes,\n",
    "    shape_inner_amplitude=p_shape_inner_amplitude,\n",
    "    shape_outer_amplitude=p_shape_outer_amplitude,\n",
    "    display_image=False # Show the disk we're about to render\n",
    ")\n",
    "\n",
    "# 2. Calculate animation time window\n",
    "isco_radius = 6.0 * p_mass_of_black_hole\n",
    "orbital_period_at_isco = 2 * np.pi * np.sqrt(isco_radius**3 / p_mass_of_black_hole)\n",
    "animation_duration = orbital_period_at_isco * p_anim_orbits_at_isco\n",
    "animation_end_time = p_anim_start_time + animation_duration\n",
    "\n",
    "print(f\"\\nAnimation will run from t={p_anim_start_time:.2f} M to t={animation_end_time:.2f} M (Duration: {animation_duration:.2f} M).\")\n",
    "\n",
    "# --- Important: Do you want to save the light blueprints?\n",
    "save_blueprints= False\n",
    "\n",
    "# 3. Generate all the PNG frames for the animation\n",
    "generate_spinning_disk_animation_frames(\n",
    "    num_frames=p_anim_num_frames,\n",
    "    total_animation_duration=animation_duration,\n",
    "    start_time_offset=p_anim_start_time,\n",
    "    project_dir=p_light_integrator_dir, # The C code still runs from its own directory\n",
    "    executable_name=\"photon_geodesic_integrator\",\n",
    "    base_par_filename=\"photon_geodesic_integrator.par\",\n",
    "    blueprint_folder=blueprint_folder, # Pass the corrected, absolute path\n",
    "    frames_folder=frames_folder,\n",
    "    output_pixel_width=p_animation_pixel_width,\n",
    "    source_image_width=p_source_physical_width,\n",
    "    sphere_image=p_sphere_texture_file,\n",
    "    source_image=source_disk_texture,\n",
    "    window_width=p_window_width,\n",
    "    gamma=p_gamma,\n",
    "    lambda_min_nm=p_lambda_min_nm,\n",
    "    lambda_max_nm=p_lambda_max_nm,\n",
    "    intensity_scale=p_intensity_scale,\n",
    "    save_blueprints= save_blueprints\n",
    ")\n",
    "# 4. Encode the generated frames into an MP4 video\n",
    "encode_video_from_frames(\n",
    "    image_folder=p_anim_frames_folder,\n",
    "    output_video_path=p_anim_video_file,\n",
    "    frame_rate=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea76a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_video_from_frames(\n",
    "    image_folder=p_anim_frames_folder,\n",
    "    output_video_path=p_anim_video_file,\n",
    "    frame_rate=8\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Jupyter notebook)",
   "language": "python",
   "name": "docs-project-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
